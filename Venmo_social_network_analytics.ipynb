{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Venmo Homework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfTnXcij7Vil",
        "colab_type": "text"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZYma3NB7ZQU",
        "colab_type": "text"
      },
      "source": [
        "This script employs pyspark as the main tool to analyze the spending behavior and the social network of Venmo users using their transactional data. The script consists of 5 parts:\n",
        "1. Initial set-up <br/>\n",
        "2. Import datasets <br/>\n",
        "3. Part 1 Text Analytics <br/>\n",
        "4. Part 2 Social Network Analytics <br/>\n",
        "5. Part 3 Predictive Analytics with MLlib <br/>\n",
        "\n",
        "As the size of the dataset is large, we suggest users of the script running on google colab or clusters. It is also recommended that users save the regression input tables of Part 3 as parquet files and then estimate predictive models, as parquet files will dramatically improve the speed of running the regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIq_-p3iSNkv",
        "colab_type": "text"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJVgehasfoRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgD5Mm7ffv68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-1.8.0-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VISHnnvpgWdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.config(\"spark.driver.memory\", \"10g\").appName('Homework2').getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUBbc6vEfZiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install emoji\n",
        "!pip install pyspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDAW4cZOe0RL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import emoji\n",
        "from emoji import *\n",
        "import string\n",
        "import re\n",
        "import pyspark\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession, SQLContext, Window\n",
        "from pyspark.sql.functions import lit, sum, col, min, when, pandas_udf, PandasUDFType, regexp_extract\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType\n",
        "from pyspark.conf import SparkConf\n",
        "SparkSession.builder.config(conf=SparkConf())\n",
        "from pyspark.ml.linalg import Vector\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "import networkx as nx\n",
        "from itertools import groupby\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxmR4rMPS9uG",
        "colab_type": "text"
      },
      "source": [
        "# Import Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTitqL99UKb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this helps you connect to the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duIWQUEHgJKP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1rSB7aWZTuX",
        "colab_type": "code",
        "outputId": "d986d32a-18a7-46d6-9161-e45c6731e04a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls '/content/drive/My Drive/ConFiveDance/code/VenmoSample.snappy.parquet'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/drive/My Drive/ConFiveDance/code/VenmoSample.snappy.parquet'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5T-1QkMS805",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputdata = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/VenmoSample.snappy.parquet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTHLvr1FCDMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Import text dictionary\n",
        "text_dict = spark.read.csv('/content/drive/My Drive/ConFiveDance/code/Venmo_Word_Classification_Dictonary.csv', header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIuXE7PdCGWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Import emoji dictionary\n",
        "emoji_dict = spark.read.csv('/content/drive/My Drive/ConFiveDance/code/Venmo_Emoji_Classification_Dictionary.csv', header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpMD5h-bV0Lc",
        "colab_type": "text"
      },
      "source": [
        "#Part 1 Text Analytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0gqLu3KubYV",
        "colab_type": "text"
      },
      "source": [
        "## Q1 Classify Venmo‚Äôs transactions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72Bmb9vIR1Ey",
        "colab_type": "text"
      },
      "source": [
        "### Dictionaries Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_Dn2sfCpI6r",
        "colab_type": "text"
      },
      "source": [
        "Text Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1cwREP0pNC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##make text dictionary lists based on categories\n",
        "txt_lst_Event=[row['Event'] for row in text_dict.collect()]\n",
        "txt_lst_Event=[i for i in txt_lst_Event if i!= None]\n",
        "txt_lst_Travel=[row['Travel'] for row in text_dict.collect()]\n",
        "txt_lst_Travel=[i for i in txt_lst_Travel if i!= None]\n",
        "txt_lst_Food=[row['Food'] for row in text_dict.collect()]\n",
        "txt_lst_Food=[i for i in txt_lst_Food if i!= None]\n",
        "txt_lst_Activity=[row['Activity'] for row in text_dict.collect()]\n",
        "txt_lst_Activity=[i for i in txt_lst_Activity if i!= None]\n",
        "txt_lst_Transportation=[row['Transportation'] for row in text_dict.collect()]\n",
        "txt_lst_Transportation=[i for i in txt_lst_Transportation if i!= None]\n",
        "txt_lst_People=[row['People'] for row in text_dict.collect()]\n",
        "txt_lst_People=[i for i in txt_lst_People if i!= None]\n",
        "txt_lst_Utility=[row['Utility'] for row in text_dict.collect()]\n",
        "txt_lst_Utility=[i for i in txt_lst_Utility if i!= None]\n",
        "txt_lst_Cash=[row['Cash'] for row in text_dict.collect()]\n",
        "txt_lst_Cash=[i for i in txt_lst_Cash if i!= None]\n",
        "txt_lst_Illegal_Sarcasm=[row['Illegal/Sarcasm'] for row in text_dict.collect()]\n",
        "txt_lst_Illegal_Sarcasm=[i for i in txt_lst_Illegal_Sarcasm if i!= None]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1gAv9BTpNAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Create a list that contains all words that can be found in the text dictionary\n",
        "txt_lst = txt_lst_Event+txt_lst_Travel+txt_lst_Food+txt_lst_Activity+txt_lst_Transportation+txt_lst_People+txt_lst_Utility+txt_lst_Cash+txt_lst_Illegal_Sarcasm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVFLdQhvp3eI",
        "colab_type": "text"
      },
      "source": [
        "Emoji Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5J-1rtZAxDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Clean data: remove messy symbols\n",
        "emoji_pd=emoji_dict.toPandas()\n",
        "emoji_pd = emoji_pd.applymap(lambda x:x[0] if x is not None else x)\n",
        "emoji_spark=spark.createDataFrame(emoji_pd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVZLiAYnAxKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##make emoji dictionary lists based on categories\n",
        "emoji_lst_Event=[row['Event'] for row in emoji_spark.collect()]\n",
        "emoji_lst_Event=[i for i in emoji_lst_Event if i!= None]\n",
        "emoji_lst_Travel=[row['Travel'] for row in emoji_spark.collect()]\n",
        "emoji_lst_Travel=[i for i in emoji_lst_Travel if i!= None]\n",
        "emoji_lst_Food=[row['Food'] for row in emoji_spark.collect()]\n",
        "emoji_lst_Food=[i for i in emoji_lst_Food if i!= None]\n",
        "emoji_lst_Activity=[row['Activity'] for row in emoji_spark.collect()]\n",
        "emoji_lst_Activity=[i for i in emoji_lst_Activity if i!= None]\n",
        "emoji_lst_Transportation=[row['Transportation'] for row in emoji_spark.collect()]\n",
        "emoji_lst_Transportation=[i for i in emoji_lst_Transportation if i!= None]\n",
        "emoji_lst_People=[row['People'] for row in emoji_spark.collect()]\n",
        "emoji_lst_People=[i for i in emoji_lst_People if i!= None]\n",
        "emoji_lst_Utility=[row['Utility'] for row in emoji_spark.collect()]\n",
        "emoji_lst_Utility=[i for i in emoji_lst_Utility if i!= None]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06yOVVll7pls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Create a list that contains all emojis that can be found in the emoji dictionary\n",
        "emoji_lst=emoji_lst_Event+emoji_lst_Travel+emoji_lst_Food+emoji_lst_Activity+emoji_lst_Transportation+emoji_lst_People+emoji_lst_Utility"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYQxjdzjqYLT",
        "colab_type": "text"
      },
      "source": [
        "Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koHg4aW63Er5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##A function that takes a word or a emoji as input and returns the category of the input\n",
        "def to_category(wd):\n",
        "    if wd in txt_lst_Event or wd in emoji_lst_Event:\n",
        "        return 'Event'\n",
        "    elif wd in txt_lst_Travel or wd in emoji_lst_Travel:\n",
        "        return 'Travel'\n",
        "    elif wd in txt_lst_Food or wd in emoji_lst_Food:\n",
        "        return 'Food'\n",
        "    elif wd in txt_lst_Activity or wd in emoji_lst_Activity:\n",
        "        return 'Activity'\n",
        "    elif wd in txt_lst_Transportation or wd in emoji_lst_Transportation:\n",
        "        return 'Transportation'\n",
        "    elif wd in txt_lst_People or wd in emoji_lst_People:\n",
        "        return 'People'\n",
        "    elif wd in txt_lst_Utility or wd in emoji_lst_Utility:\n",
        "        return 'Utility'\n",
        "    elif wd in txt_lst_Cash:\n",
        "        return 'Cash'\n",
        "    elif wd in txt_lst_Illegal_Sarcasm:\n",
        "        return 'Illegal_Sarcasm'\n",
        "    else:\n",
        "        return 'Not_classified'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQc6w5ZBwdpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##A funtion that takes strings as input and returns the category of the string\n",
        "##If a single string involves more than one category, the returned category should be the one that has the greatest occurrance\n",
        "def classify(string):\n",
        "\n",
        "    if bool(emoji.get_emoji_regexp().search(string)) is True:\n",
        "    #case when the string contains emoji\n",
        "        #create a list that includes all the emojis in the string\n",
        "        emoji_in_str=list(filter(lambda x:  x in string, emoji_lst))\n",
        "    else:\n",
        "        #if the string does not contain any emoji, create an empty list\n",
        "        emoji_in_str=[]\n",
        "\n",
        "    #letters to lower case\n",
        "    new_str=string.lower()\n",
        "    #find all numbers in the string and replace with a space\n",
        "    new_str=re.sub(r'[0-9]+', ' ', new_str)\n",
        "    #find all special symbols in the string and replace with a space\n",
        "    new_str=re.sub('[^A-Za-z0-9]+', ' ', new_str)\n",
        "    #find all emojis in the string and replace with a space\n",
        "    no_emoji=re.sub('\\u00a9|\\u00ae|[\\u2000-\\u3300]|\\ud83c[\\ud000-\\udfff]|\\ud83d[\\ud000-\\udfff]|\\ud83e[\\ud000-\\udfff]+',' ',new_str)\n",
        "    #replace all >1 spaces with a space\n",
        "    no_emoji=re.sub('\\s+',' ',no_emoji)\n",
        "    #split the text only string by space into a list of word(s)\n",
        "    txt_only_lst=no_emoji.split()\n",
        "    ##filter the list of words and only keep the words which occur in the text dictionary\n",
        "    txt_in_list=list(filter(lambda x:  x in txt_only_lst, txt_lst))\n",
        "    #combine the list with emojis and the list with words into a new list\n",
        "    comb_lst=txt_in_list+emoji_in_str\n",
        "\n",
        "    if comb_lst==[]:\n",
        "    #when none of the emojis nor words has a match in category, the string has no category\n",
        "        cat='Not_classified'\n",
        "    else:\n",
        "        #create a new list that lists the categories of the elements in the string\n",
        "        cat_lst=list(map(to_category, comb_lst))\n",
        "        #find the category that has the greatest occurrance in the string\n",
        "        cat=max(cat_lst, key=cat_lst.count)\n",
        "\n",
        "    return cat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gEXyQOxwqSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import *\n",
        "udf_classify=F.udf(classify, StringType())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqA6eAa_5enQ",
        "colab_type": "code",
        "outputId": "e5b51f27-428a-4fa1-fc02-cddb008c38c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "#add a new column to the original dataset classifying the category of description for each transaction\n",
        "input_with_cat=inputdata.withColumn('category',udf_classify('description'))\n",
        "input_with_cat.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+----------------+-------------------+------------+-----------+--------------------+---------------+\n",
            "|  user1|  user2|transaction_type|           datetime| description|is_business|            story_id|       category|\n",
            "+-------+-------+----------------+-------------------+------------+-----------+--------------------+---------------+\n",
            "|1218774|1528945|         payment|2015-11-27 10:48:19|        Uber|      false|5657c473cd03c9af2...| Transportation|\n",
            "|5109483|4782303|         payment|2015-06-17 11:37:04|      Costco|      false|5580f9702b64f70ab...|           Food|\n",
            "|4322148|3392963|         payment|2015-06-19 07:05:31|Sweaty balls|      false|55835ccb1a624b14a...|Illegal_Sarcasm|\n",
            "| 469894|1333620|          charge|2016-06-03 23:34:13|          üé•|      false|5751b185cd03c9af2...|          Event|\n",
            "|2960727|3442373|         payment|2016-05-29 23:23:42|           ‚ö°|      false|574b178ecd03c9af2...|        Utility|\n",
            "+-------+-------+----------------+-------------------+------------+-----------+--------------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfuQDgt65qUI",
        "colab_type": "text"
      },
      "source": [
        "## Q2 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQSEE_6J347b",
        "colab_type": "text"
      },
      "source": [
        "### Emoji Only Percentage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl-QzBzk6bk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##the function takes in a string, return 1 if it is a emoji-only string, and 0 otherwise\n",
        "def emoji_only(desc):\n",
        "    if all(ele in emoji.UNICODE_EMOJI for ele in desc) is True:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu1ZWJZr-gdh",
        "colab_type": "code",
        "outputId": "93e64d6e-3cc2-4ada-8d48-03dc264b5dea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "##add a new column to the original table labeling if the description of transaction is emoji only\n",
        "udf_emoji_only=F.udf(emoji_only, StringType())\n",
        "with_label=inputdata.withColumn('Emoji_Only',udf_emoji_only('description'))\n",
        "with_label.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+----------------+-------------------+------------+-----------+--------------------+----------+\n",
            "|  user1|  user2|transaction_type|           datetime| description|is_business|            story_id|Emoji_Only|\n",
            "+-------+-------+----------------+-------------------+------------+-----------+--------------------+----------+\n",
            "|1218774|1528945|         payment|2015-11-27 10:48:19|        Uber|      false|5657c473cd03c9af2...|         0|\n",
            "|5109483|4782303|         payment|2015-06-17 11:37:04|      Costco|      false|5580f9702b64f70ab...|         0|\n",
            "|4322148|3392963|         payment|2015-06-19 07:05:31|Sweaty balls|      false|55835ccb1a624b14a...|         0|\n",
            "| 469894|1333620|          charge|2016-06-03 23:34:13|          üé•|      false|5751b185cd03c9af2...|         1|\n",
            "|2960727|3442373|         payment|2016-05-29 23:23:42|           ‚ö°|      false|574b178ecd03c9af2...|         1|\n",
            "+-------+-------+----------------+-------------------+------------+-----------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r451EHNrBVOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext\n",
        "sc =SparkContext.getOrCreate()\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnJLdSc3AleN",
        "colab_type": "code",
        "outputId": "b978f711-187f-4186-debe-f41a9252b93f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "##sum up the number of emoji_only transactions\n",
        "with_label.registerTempTable('with_label_tbl')\n",
        "table=sqlContext.sql('select sum(Emoji_Only) as sum_emoji_only from with_label_tbl')\n",
        "table.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+\n",
            "|sum_emoji_only|\n",
            "+--------------+\n",
            "|     1665871.0|\n",
            "+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PivpHeM4B_-2",
        "colab_type": "code",
        "outputId": "72feb65c-e8db-4022-89fc-defe9c7a6628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "##emoji only percentage\n",
        "print(1665871.0/inputdata.count())\n",
        "print(\"{0:.0%}\".format(1665871.0/inputdata.count()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.23419638901935952\n",
            "23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIiZNKjOyQYS",
        "colab_type": "text"
      },
      "source": [
        "### Top 5 Most Popular Emojis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM1aasiLKw4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##the function extracts all emojis from the input string\n",
        "def extract_emojis(string):\n",
        "    return ''.join(c for c in string if c in emoji.UNICODE_EMOJI)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PzS9HFwH_ZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##add a column to the inputdata with the extracted emojis from description\n",
        "udf_extract_emojis=F.udf(extract_emojis, StringType())\n",
        "with_emoji_col=inputdata.withColumn('emoji',udf_extract_emojis('description'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iSwNCyjTnFU",
        "colab_type": "code",
        "outputId": "40376db6-a1a8-4ddf-e231-31aa599ae3a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "##fill the blanks in emoji column with null values\n",
        "with_emoji_col = with_emoji_col.withColumn('emoji', when(col('emoji') == '', None).otherwise(col('emoji')))\n",
        "with_emoji_col.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+----------------+-------------------+------------+-----------+--------------------+-----+\n",
            "|  user1|  user2|transaction_type|           datetime| description|is_business|            story_id|emoji|\n",
            "+-------+-------+----------------+-------------------+------------+-----------+--------------------+-----+\n",
            "|1218774|1528945|         payment|2015-11-27 10:48:19|        Uber|      false|5657c473cd03c9af2...| null|\n",
            "|5109483|4782303|         payment|2015-06-17 11:37:04|      Costco|      false|5580f9702b64f70ab...| null|\n",
            "|4322148|3392963|         payment|2015-06-19 07:05:31|Sweaty balls|      false|55835ccb1a624b14a...| null|\n",
            "| 469894|1333620|          charge|2016-06-03 23:34:13|          üé•|      false|5751b185cd03c9af2...|   üé•|\n",
            "|2960727|3442373|         payment|2016-05-29 23:23:42|           ‚ö°|      false|574b178ecd03c9af2...|    ‚ö°|\n",
            "+-------+-------+----------------+-------------------+------------+-----------+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSgNlQtIYMvY",
        "colab_type": "code",
        "outputId": "b4098823-0857-46eb-9d47-a30a0d8982d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "##filter the rows and only keep the transactions which are emoji_only\n",
        "only_emoji=with_emoji_col.filter(with_emoji_col.emoji.isNotNull())\n",
        "only_emoji.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-------+----------------+-------------------+-----------+-----------+--------------------+-----+\n",
            "|   user1|  user2|transaction_type|           datetime|description|is_business|            story_id|emoji|\n",
            "+--------+-------+----------------+-------------------+-----------+-----------+--------------------+-----+\n",
            "|  469894|1333620|          charge|2016-06-03 23:34:13|         üé•|      false|5751b185cd03c9af2...|   üé•|\n",
            "| 2960727|3442373|         payment|2016-05-29 23:23:42|          ‚ö°|      false|574b178ecd03c9af2...|    ‚ö°|\n",
            "| 5317324|3942984|         payment|2016-01-04 09:11:25|         üë†|      false|5689c6bdcd03c9af2...|   üë†|\n",
            "| 4238868|4879587|         payment|2015-10-04 08:28:01|         üç∫|      false|561080a1cd03c9af2...|   üç∫|\n",
            "|11719500|8702716|         payment|2016-07-07 21:40:39|          ‚õΩ|      false|577e69e723e064eac...|    ‚õΩ|\n",
            "+--------+-------+----------------+-------------------+-----------+-----------+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY0iDKkCPZG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##extract all the emojis from emoji column and put them into a list\n",
        "##each element in the list is a single emoji\n",
        "emoji_lst=[row.emoji for row in only_emoji.collect()]\n",
        "emoji_lst=''.join(emoji_lst)\n",
        "lst_all_emoji=[]\n",
        "for item in emoji_lst:\n",
        "    lst_all_emoji.append(item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K_nAZwxOQyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##create a dictionary to list out the occurrances of each emoji\n",
        "emoji_num = {value: len(list(freq)) for value, freq in groupby(sorted(lst_all_emoji))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_iQZd4KOQv6",
        "colab_type": "code",
        "outputId": "c9c4f194-b722-4cc3-da7b-1bbe868c2595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "##sort the dictionary by occurrances of emojis in descending order\n",
        "emoji_sorted = sorted(emoji_num, key=emoji_num.get, reverse=True)\n",
        "order=0\n",
        "for i in emoji_sorted:\n",
        "    print(i, emoji_num[i])\n",
        "    order+=1\n",
        "    if order == 5: break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "üçï 215039\n",
            "üçª 145233\n",
            "üí∏ 124727\n",
            "üç∑ 111157\n",
            "üéâ 94327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvduUebKyi3q",
        "colab_type": "text"
      },
      "source": [
        "### Top 3 most popular emoji categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvNgEjoLyPqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##create a for loop to count the occurrences of emojis in each category\n",
        "count_Event=0\n",
        "count_Travel=0\n",
        "count_Food=0\n",
        "count_Activity=0\n",
        "count_Transportation=0\n",
        "count_People=0\n",
        "count_Utility=0\n",
        "count_Not_classified=0\n",
        "\n",
        "for item in emoji_lst:\n",
        "    if item in emoji_lst_Event:\n",
        "        count_Event=count_Event+1\n",
        "    elif item in emoji_lst_Travel:\n",
        "        count_Travel=count_Travel+1\n",
        "    elif item in emoji_lst_Food:\n",
        "        count_Food=count_Food+1\n",
        "    elif item in emoji_lst_Activity:\n",
        "        count_Activity=count_Activity+1\n",
        "    elif item in emoji_lst_Transportation:\n",
        "        count_Transportation=count_Transportation+1\n",
        "    elif item in emoji_lst_People:\n",
        "        count_People=count_People+1\n",
        "    elif item in emoji_lst_Utility:\n",
        "        count_Utility=count_Utility+1\n",
        "    else:\n",
        "        count_Not_classified=count_Not_classified+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhj1n6RQNQFn",
        "colab_type": "code",
        "outputId": "9254c8ac-30ac-4743-caff-b11000999000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "##list the categories along with the occurrances\n",
        "d={'Category': ['Event', 'Travel', 'Food', 'Activity', 'Transportation', 'People', 'Utility'],'Count': [count_Event, count_Travel, count_Food, count_Activity, count_Transportation, count_People, count_Utility]}\n",
        "cnt_cat = pd.DataFrame(data=d)\n",
        "cnt_cat.sort_values(by='Count', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Food</td>\n",
              "      <td>1744390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>People</td>\n",
              "      <td>1113540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Utility</td>\n",
              "      <td>430868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Activity</td>\n",
              "      <td>423988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Transportation</td>\n",
              "      <td>258830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Event</td>\n",
              "      <td>218497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Travel</td>\n",
              "      <td>111848</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Category    Count\n",
              "2            Food  1744390\n",
              "5          People  1113540\n",
              "6         Utility   430868\n",
              "3        Activity   423988\n",
              "4  Transportation   258830\n",
              "0           Event   218497\n",
              "1          Travel   111848"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAPeaN07yuB6",
        "colab_type": "text"
      },
      "source": [
        "## Q3 Spending Profile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwgM-UQDyw94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_with_cat.registerTempTable('input_with_cat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDjUXueGyw74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##create a table to list the users, categories, transaction(s) per category and percentage of each category for each user\n",
        "trans_profile=spark.sql(\"select user1, Category, count(*) as transaction_per_category, round(count(*)/sum(count(*)) over(partition by user1), 2) as ratio from input_with_cat where transaction_type='payment' group by user1, Category order by user1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNMLbd1ZSLAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trans_profile.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4YJqUQ2yw5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pivot the table to create a spending profile for each user\n",
        "profile=trans_profile.groupby(trans_profile.user1).pivot(\"Category\").avg(\"ratio\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52WzJfrhHAje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "profile.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0aBIHVMLbVA",
        "colab_type": "text"
      },
      "source": [
        "## Q4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtQa24N5LamX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use window function to get the date of the first transaction of each user1\n",
        "window = Window.partitionBy(\"user1\").orderBy(\"datetime\") \n",
        "\n",
        "dynamic_spending = input_with_cat.select('user1', 'category', 'datetime').withColumn(\"start_date\", min(\"datetime\").over(window))\n",
        "#dynamic_spending.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PB_VIVZLgcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dynamic_spending.createOrReplaceTempView(\"table_ds1\")\n",
        "dynamic_spending_1 = spark.sql(\"\"\"SELECT user1, category, datetime, start_date, \n",
        "                           ceil(datediff(datetime, start_date)/30) AS lifetime\n",
        "                           FROM table_ds1\n",
        "                           ORDER BY user1, datetime\"\"\")\n",
        "#dynamic_spending_1.show(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYacezm1MXUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select transaction within one year \n",
        "dynamic_spending_1.createOrReplaceTempView(\"table_ds2\")\n",
        "user_lifetime.createOrReplaceTempView(\"table_ul1\")\n",
        "dynamic_spending_one_year1 = spark.sql('''\n",
        "                                      SELECT user1, Category, lifetime,  \\\n",
        "                                            count(*) as transaction_per_category_per_lifetime,  \\\n",
        "                                            round(count(*)/sum(count(*)) over(partition by user1,lifetime), 2) as ratio  \n",
        "                                      FROM\n",
        "                                      (SELECT user1, category, lifetime\n",
        "                                      FROM table_ds2\n",
        "                                      WHERE lifetime <= 12)\n",
        "                                      group by user1, lifetime, Category \n",
        "                                      order by user1, lifetime\n",
        "                                      ''')\n",
        "\n",
        "#dynamic_spending_one_year1.show(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bs0qeEHMOrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pivot the tables group by user1 and lifetime\n",
        "categories = sorted(dynamic_spending_one_year1.select(\"Category\").distinct().rdd.map(lambda row: row[0]).collect())\n",
        "\n",
        "cols1 = [when(col(\"Category\") == cats, col(\"ratio\")).otherwise(None).alias(cats) for cats in categories]\n",
        "\n",
        "maxs1 = [F.max(col(cats)).alias(cats) for cats in categories]\n",
        "\n",
        "dynamic_profile = (dynamic_spending_one_year1.select(col(\"user1\"),col(\"lifetime\"), *cols1)\\\n",
        "                   .groupBy(\"user1\", \"lifetime\").agg(*maxs1).na.fill(0)\\\n",
        "                   .orderBy(\"user1\", \"lifetime\")\n",
        "                   )\n",
        "dynamic_profile.createOrReplaceTempView(\"table_dp\")\n",
        "#dynamic_profile.show(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBSLmnplMRXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store the table\n",
        "dynamic_profile.coalesce(1).write.format(\"parquet\").mode(\"append\").save(\"dynamic_profile.parquet\") \n",
        "!mv dynamic_profile.parquet /content/drive/My\\ Drive/ConFiveDance/code     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmhiyTsaSBbh",
        "colab_type": "text"
      },
      "source": [
        "# Part 2 Social Network Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZI_F6eQqma5",
        "colab_type": "text"
      },
      "source": [
        "## Q5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUIqvSZhSKsf",
        "colab_type": "code",
        "outputId": "d78b0820-ad47-458c-c8e9-0fcb998ebf7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "inputdata.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+----------------+-------------------+------------+-----------+--------------------+\n",
            "|  user1|  user2|transaction_type|           datetime| description|is_business|            story_id|\n",
            "+-------+-------+----------------+-------------------+------------+-----------+--------------------+\n",
            "|1218774|1528945|         payment|2015-11-27 10:48:19|        Uber|      false|5657c473cd03c9af2...|\n",
            "|5109483|4782303|         payment|2015-06-17 11:37:04|      Costco|      false|5580f9702b64f70ab...|\n",
            "|4322148|3392963|         payment|2015-06-19 07:05:31|Sweaty balls|      false|55835ccb1a624b14a...|\n",
            "| 469894|1333620|          charge|2016-06-03 23:34:13|          üé•|      false|5751b185cd03c9af2...|\n",
            "|2960727|3442373|         payment|2016-05-29 23:23:42|           ‚ö°|      false|574b178ecd03c9af2...|\n",
            "+-------+-------+----------------+-------------------+------------+-----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlZypSelQOX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "venmo = inputdata.rdd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q88v4V1uPjFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# union all the transaction pairs with a list reversing the transactions\n",
        "user_list = venmo.map(lambda row: (row[0], row[1])).distinct().union(venmo.map(lambda row: (row[1], row[0])).distinct())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtJvTV_FY1XA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reduce to key, [values] pairs, i.e. find friends\n",
        "find_friends = user_list.groupByKey()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jur5vgdTY7Qu",
        "colab_type": "code",
        "outputId": "3268734d-4153-415a-e0d3-c9fb280c62f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "find_friends.mapValues(list).take(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1218774, [1528945, 2299797, 6784812, 2248062, 825037]),\n",
              " (4322148,\n",
              "  [3392963,\n",
              "   4473959,\n",
              "   2648089,\n",
              "   3622559,\n",
              "   4404526,\n",
              "   3923033,\n",
              "   3633626,\n",
              "   6547092,\n",
              "   4524457,\n",
              "   4323622,\n",
              "   3847831,\n",
              "   6547092,\n",
              "   558617,\n",
              "   3949387,\n",
              "   6547092,\n",
              "   3392963,\n",
              "   3622559,\n",
              "   3392963,\n",
              "   3392963,\n",
              "   1048528,\n",
              "   6547092]),\n",
              " (3977544, [2709470, 3656888, 3679548, 6664605, 2709470]),\n",
              " (3766386,\n",
              "  [4209061,\n",
              "   4209061,\n",
              "   4209061,\n",
              "   4209061,\n",
              "   4209061,\n",
              "   1372637,\n",
              "   2817693,\n",
              "   3996405,\n",
              "   2617050,\n",
              "   3996405,\n",
              "   4746672,\n",
              "   3996405,\n",
              "   4746672,\n",
              "   1372637,\n",
              "   4289112,\n",
              "   4209061,\n",
              "   2189993,\n",
              "   3996405,\n",
              "   4289112,\n",
              "   4746672,\n",
              "   2281429,\n",
              "   4289112,\n",
              "   4289112,\n",
              "   2189993,\n",
              "   2617050,\n",
              "   1310304,\n",
              "   4209061,\n",
              "   1531371]),\n",
              " (6843582, [7308338, 2981211, 3513313, 855381]),\n",
              " (4238868, [4879587, 3705679, 8478573, 2473465, 3785350, 2473465, 6783538]),\n",
              " (11719500, [8702716, 8702716, 8702716]),\n",
              " (613908,\n",
              "  [3045405,\n",
              "   711462,\n",
              "   283445,\n",
              "   758725,\n",
              "   616362,\n",
              "   3149560,\n",
              "   761582,\n",
              "   645129,\n",
              "   581782,\n",
              "   645129]),\n",
              " (241386,\n",
              "  [2580543,\n",
              "   2337750,\n",
              "   3387170,\n",
              "   5198327,\n",
              "   2657540,\n",
              "   3020638,\n",
              "   218243,\n",
              "   2806560,\n",
              "   3402153,\n",
              "   5020329]),\n",
              " (7077930, [2219363, 1581201, 8596553, 6347014, 6077312, 6347014, 8593653])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLGLuA6zTFT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "find_friends_as_map = find_friends.mapValues(list).collectAsMap()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCukpPUY00UC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fof = find_friends.map(lambda row : fndoffnd_func(row, find_friends_as_map))  \n",
        "\n",
        "def fndoffnd_func(row, rdd):\n",
        "    res = set()\n",
        "    for key in row[1]:\n",
        "        set_bin = set(rdd[key])\n",
        "        res.update(set_bin)\n",
        "    return (row[0], list(res))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxhj93QC0252",
        "colab_type": "code",
        "outputId": "6731cf84-94f3-4b56-82c9-6fa59ac31e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fof.take(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(265062,\n",
              "  [455168,\n",
              "   371969,\n",
              "   487425,\n",
              "   417285,\n",
              "   602118,\n",
              "   694277,\n",
              "   1595145,\n",
              "   1394441,\n",
              "   1108748,\n",
              "   501006,\n",
              "   3266578,\n",
              "   746260,\n",
              "   601365,\n",
              "   1127956,\n",
              "   398103,\n",
              "   245781,\n",
              "   1085718,\n",
              "   383011,\n",
              "   479269,\n",
              "   336166,\n",
              "   1170474,\n",
              "   1679147,\n",
              "   334635,\n",
              "   236842,\n",
              "   1127731,\n",
              "   5269560,\n",
              "   616249,\n",
              "   759869,\n",
              "   931391,\n",
              "   212546,\n",
              "   539459,\n",
              "   937542,\n",
              "   416842,\n",
              "   819275,\n",
              "   612176,\n",
              "   437841,\n",
              "   1501009,\n",
              "   1469526,\n",
              "   499288,\n",
              "   265062,\n",
              "   1300582,\n",
              "   703080,\n",
              "   6671721,\n",
              "   797546,\n",
              "   488811,\n",
              "   339814,\n",
              "   397160,\n",
              "   1256816,\n",
              "   1099633,\n",
              "   215668,\n",
              "   321397,\n",
              "   1404277,\n",
              "   1587576,\n",
              "   683385,\n",
              "   1236348,\n",
              "   1106556,\n",
              "   2766210,\n",
              "   10167939,\n",
              "   140165,\n",
              "   266120,\n",
              "   410250,\n",
              "   400273,\n",
              "   590483,\n",
              "   1548949,\n",
              "   145055,\n",
              "   1867169,\n",
              "   1628071,\n",
              "   322728,\n",
              "   1534123,\n",
              "   933804,\n",
              "   137137,\n",
              "   548530,\n",
              "   520122,\n",
              "   557755,\n",
              "   1313469,\n",
              "   863681,\n",
              "   725443,\n",
              "   168649,\n",
              "   449228,\n",
              "   144850,\n",
              "   1335507,\n",
              "   1814997,\n",
              "   626652,\n",
              "   2205151,\n",
              "   1511393,\n",
              "   339940,\n",
              "   1403879,\n",
              "   831721,\n",
              "   346090,\n",
              "   619243,\n",
              "   527339,\n",
              "   314099,\n",
              "   3988983,\n",
              "   342268]),\n",
              " (332730, [834305, 851817, 4248588, 848592, 1941265, 4929107, 332730])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8vOiJbcpoMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fof_2d_only = fof.map(lambda row: (row[0], set(row[1]).difference(set(find_friends_as_map[row[0]]))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLXVG9fHqKJv",
        "colab_type": "code",
        "outputId": "1fb0d2fc-425e-4741-e3ad-6ff76a854292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fof_2d_only.take(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(420198,\n",
              "  {83671,\n",
              "   104644,\n",
              "   154182,\n",
              "   184178,\n",
              "   191654,\n",
              "   192428,\n",
              "   193340,\n",
              "   194311,\n",
              "   215507,\n",
              "   220739,\n",
              "   236645,\n",
              "   282947,\n",
              "   331169,\n",
              "   341118,\n",
              "   351854,\n",
              "   369623,\n",
              "   390915,\n",
              "   393292,\n",
              "   393629,\n",
              "   396869,\n",
              "   397036,\n",
              "   408019,\n",
              "   412982,\n",
              "   419998,\n",
              "   420198,\n",
              "   422440,\n",
              "   452328,\n",
              "   475487,\n",
              "   480487,\n",
              "   486116,\n",
              "   489047,\n",
              "   502180,\n",
              "   505873,\n",
              "   538080,\n",
              "   551513,\n",
              "   586915,\n",
              "   593376,\n",
              "   663478,\n",
              "   680974,\n",
              "   698612,\n",
              "   712878,\n",
              "   807315,\n",
              "   835911,\n",
              "   888317,\n",
              "   888373,\n",
              "   894818,\n",
              "   970960,\n",
              "   1014089,\n",
              "   1067539,\n",
              "   1133428,\n",
              "   1166049,\n",
              "   1192870,\n",
              "   1202352,\n",
              "   1228224,\n",
              "   1266168,\n",
              "   1279229,\n",
              "   1336919,\n",
              "   1405226,\n",
              "   1526677,\n",
              "   1603509,\n",
              "   1628081,\n",
              "   1634909,\n",
              "   1667550,\n",
              "   1701441,\n",
              "   1894637,\n",
              "   1999457,\n",
              "   2069446,\n",
              "   2161509,\n",
              "   2235103,\n",
              "   2270994,\n",
              "   2464419,\n",
              "   2592348,\n",
              "   2753587,\n",
              "   3324076,\n",
              "   3674843,\n",
              "   4280976,\n",
              "   4317759,\n",
              "   4786765}),\n",
              " (2309874,\n",
              "  {414270,\n",
              "   421558,\n",
              "   448071,\n",
              "   580823,\n",
              "   597241,\n",
              "   600363,\n",
              "   627502,\n",
              "   647030,\n",
              "   655023,\n",
              "   726161,\n",
              "   1106446,\n",
              "   1114243,\n",
              "   1130802,\n",
              "   1171477,\n",
              "   1180062,\n",
              "   1309455,\n",
              "   1364102,\n",
              "   1461653,\n",
              "   1469801,\n",
              "   1490718,\n",
              "   1506807,\n",
              "   1588764,\n",
              "   1908175,\n",
              "   1983326,\n",
              "   2025990,\n",
              "   2128977,\n",
              "   2257372,\n",
              "   2277259,\n",
              "   2294513,\n",
              "   2309874,\n",
              "   2310144,\n",
              "   2375924,\n",
              "   2380974,\n",
              "   2442272,\n",
              "   2459450,\n",
              "   2463558,\n",
              "   2533067,\n",
              "   2540913,\n",
              "   2558140,\n",
              "   2561381,\n",
              "   2561472,\n",
              "   2565814,\n",
              "   2630991,\n",
              "   2865991,\n",
              "   2912422,\n",
              "   2927581,\n",
              "   2964888,\n",
              "   2986402,\n",
              "   3047738,\n",
              "   3062521,\n",
              "   3220577,\n",
              "   3268579,\n",
              "   3354297,\n",
              "   3555066,\n",
              "   3586134,\n",
              "   3719694,\n",
              "   3817928,\n",
              "   3894009,\n",
              "   3905450,\n",
              "   4228517,\n",
              "   4568181,\n",
              "   4966835,\n",
              "   5138671,\n",
              "   5733232,\n",
              "   6002736,\n",
              "   6246028,\n",
              "   7708942,\n",
              "   8417882})]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znvsEvtH1FKv",
        "colab_type": "text"
      },
      "source": [
        "## Q6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAol6OiD5cON",
        "colab_type": "text"
      },
      "source": [
        "### i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZFzUFvZ5ddX",
        "colab_type": "text"
      },
      "source": [
        "#### Number of friends"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJjRUcTn4_Lf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dynamic_social = inputdata.select('user1', 'user2', 'datetime').union(inputdata.select('user2', 'user1', 'datetime'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPFck0G55DM_",
        "colab_type": "code",
        "outputId": "3e53f7c6-8345-4e07-dc37-d52901d006b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "# use window function to get the date of the first transaction of each user1\n",
        "window = Window.partitionBy(\"user1\").orderBy(\"datetime\") \n",
        "dynamic_social = dynamic_social.withColumn(\"start_date\", min(\"datetime\").over(window))\n",
        "dynamic_social.show(50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-------+-------------------+-------------------+\n",
            "|user1|  user2|           datetime|         start_date|\n",
            "+-----+-------+-------------------+-------------------+\n",
            "| 2866|  30588|2015-09-15 21:27:00|2015-09-15 21:27:00|\n",
            "| 3918|7219365|2016-03-14 01:57:15|2016-03-14 01:57:15|\n",
            "| 3918|7219365|2016-03-14 08:25:42|2016-03-14 01:57:15|\n",
            "| 4935|  26952|2014-04-14 07:57:19|2014-04-14 07:57:19|\n",
            "| 5300|3471989|2015-12-17 10:05:27|2015-12-17 10:05:27|\n",
            "| 5300|6881591|2016-04-08 00:30:43|2015-12-17 10:05:27|\n",
            "| 5300|1682861|2016-06-05 21:40:07|2015-12-17 10:05:27|\n",
            "| 5300|4137286|2016-06-09 07:34:17|2015-12-17 10:05:27|\n",
            "| 6620|   6507|2012-04-16 21:32:43|2012-04-16 21:32:43|\n",
            "| 6620|   6606|2013-08-06 00:21:57|2012-04-16 21:32:43|\n",
            "|20735|  98941|2014-06-17 21:54:30|2014-06-17 21:54:30|\n",
            "|20735|  76245|2016-01-13 00:14:37|2014-06-17 21:54:30|\n",
            "|28170|  27438|2012-11-03 09:35:06|2012-11-03 09:35:06|\n",
            "|28170| 368813|2013-07-05 20:33:30|2012-11-03 09:35:06|\n",
            "|28170| 687334|2013-12-20 04:12:13|2012-11-03 09:35:06|\n",
            "|28170| 368813|2015-01-03 02:18:42|2012-11-03 09:35:06|\n",
            "|28170| 368813|2015-01-03 02:21:14|2012-11-03 09:35:06|\n",
            "|28170|4597539|2016-07-11 01:56:50|2012-11-03 09:35:06|\n",
            "|28170|4597539|2016-09-15 02:02:43|2012-11-03 09:35:06|\n",
            "|28759|  65628|2013-03-13 23:39:28|2013-03-13 23:39:28|\n",
            "|28759|  65628|2013-08-11 09:55:32|2013-03-13 23:39:28|\n",
            "|28759| 397277|2013-11-18 10:11:14|2013-03-13 23:39:28|\n",
            "|28759| 581923|2015-04-04 13:39:43|2013-03-13 23:39:28|\n",
            "|29054|3457112|2016-02-21 07:14:06|2016-02-21 07:14:06|\n",
            "|29054|2153890|2016-07-11 05:59:20|2016-02-21 07:14:06|\n",
            "|29894|  33385|2013-03-09 07:30:36|2013-03-09 07:30:36|\n",
            "|29894|2787407|2016-05-09 12:17:42|2013-03-09 07:30:36|\n",
            "|30903|1241150|2014-04-13 04:32:46|2014-04-13 04:32:46|\n",
            "|30903| 852163|2014-09-13 11:18:40|2014-04-13 04:32:46|\n",
            "|30903| 593848|2014-12-23 12:41:30|2014-04-13 04:32:46|\n",
            "|30903| 852163|2015-02-28 14:17:55|2014-04-13 04:32:46|\n",
            "|30903|2032414|2015-08-21 12:27:35|2014-04-13 04:32:46|\n",
            "|30970|1364887|2016-04-11 21:05:53|2016-04-11 21:05:53|\n",
            "|32396| 322255|2015-06-09 08:13:31|2015-06-09 08:13:31|\n",
            "|33602| 137025|2012-08-27 10:37:14|2012-08-27 10:37:14|\n",
            "|33602| 137025|2013-07-26 10:40:02|2012-08-27 10:37:14|\n",
            "|33602| 152043|2013-10-15 09:42:36|2012-08-27 10:37:14|\n",
            "|33602| 137025|2014-02-01 12:02:40|2012-08-27 10:37:14|\n",
            "|33602| 137025|2014-02-06 08:33:51|2012-08-27 10:37:14|\n",
            "|33602| 152043|2014-06-14 03:38:09|2012-08-27 10:37:14|\n",
            "|33602| 152043|2014-06-21 07:42:50|2012-08-27 10:37:14|\n",
            "|33602| 677386|2014-07-11 04:18:28|2012-08-27 10:37:14|\n",
            "|33602|4292661|2015-04-19 08:19:20|2012-08-27 10:37:14|\n",
            "|33602| 137025|2015-10-05 08:09:28|2012-08-27 10:37:14|\n",
            "|35820|1012471|2015-04-09 06:40:20|2015-04-09 06:40:20|\n",
            "|35820|1012471|2015-12-24 15:21:54|2015-04-09 06:40:20|\n",
            "|36525| 192549|2013-02-01 19:47:34|2013-02-01 19:47:34|\n",
            "|36525| 192549|2013-10-17 00:37:36|2013-02-01 19:47:34|\n",
            "|36525| 192549|2013-11-22 21:44:42|2013-02-01 19:47:34|\n",
            "|36525|  28192|2014-04-19 03:18:39|2013-02-01 19:47:34|\n",
            "+-----+-------+-------------------+-------------------+\n",
            "only showing top 50 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epH4ZmQu5FwC",
        "colab_type": "code",
        "outputId": "1f092d9f-9044-413a-f1bb-abad867aee89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "dynamic_social.createOrReplaceTempView(\"table1\")\n",
        "# calculate the lifetime month of the user1 for each line of transaction\n",
        "dynamic_social = spark.sql(\"\"\"SELECT user1, user2, datetime, start_date, \n",
        "                           ceil(datediff(datetime, start_date)/30) AS lifetime\n",
        "                           FROM table1 \n",
        "                           ORDER BY user1, datetime\"\"\")\n",
        "dynamic_social.show(50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-------+-------------------+-------------------+--------+\n",
            "|user1|  user2|           datetime|         start_date|lifetime|\n",
            "+-----+-------+-------------------+-------------------+--------+\n",
            "|    2|    220|2012-11-23 06:03:42|2012-11-23 06:03:42|       0|\n",
            "|    2|     43|2016-04-09 09:29:31|2012-11-23 06:03:42|      42|\n",
            "|    2|     43|2016-09-07 07:53:16|2012-11-23 06:03:42|      47|\n",
            "|    2| 191142|2016-09-26 09:56:55|2012-11-23 06:03:42|      47|\n",
            "|    3|     43|2016-06-27 01:14:37|2016-06-27 01:14:37|       0|\n",
            "|    3| 263437|2016-07-22 21:16:37|2016-06-27 01:14:37|       1|\n",
            "|    3|     52|2016-09-22 15:30:09|2016-06-27 01:14:37|       3|\n",
            "|    3|2382556|2016-10-06 10:49:45|2016-06-27 01:14:37|       4|\n",
            "|    3|2382556|2016-10-07 08:50:23|2016-06-27 01:14:37|       4|\n",
            "|    3|1079020|2016-10-07 23:37:56|2016-06-27 01:14:37|       4|\n",
            "|    3|1204190|2016-10-09 01:56:24|2016-06-27 01:14:37|       4|\n",
            "|    3|7854140|2016-10-09 03:36:13|2016-06-27 01:14:37|       4|\n",
            "|    3| 567957|2016-10-29 09:28:07|2016-06-27 01:14:37|       5|\n",
            "|    4| 122744|2012-12-03 03:35:53|2012-12-03 03:35:53|       0|\n",
            "|    4| 125527|2012-12-10 10:27:55|2012-12-03 03:35:53|       1|\n",
            "|    4| 125527|2012-12-15 05:51:12|2012-12-03 03:35:53|       1|\n",
            "|    4| 125755|2013-01-04 10:20:36|2012-12-03 03:35:53|       2|\n",
            "|    4| 968271|2014-02-04 06:51:33|2012-12-03 03:35:53|      15|\n",
            "|    4| 187560|2015-06-17 09:23:30|2012-12-03 03:35:53|      31|\n",
            "|    4|9271982|2016-03-03 12:45:57|2012-12-03 03:35:53|      40|\n",
            "|    4| 221578|2016-04-17 03:35:09|2012-12-03 03:35:53|      42|\n",
            "|    6| 676003|2014-06-28 00:18:16|2014-06-28 00:18:16|       0|\n",
            "|    6|4330489|2015-04-14 04:34:23|2014-06-28 00:18:16|      10|\n",
            "|    6| 676003|2015-08-27 00:48:57|2014-06-28 00:18:16|      15|\n",
            "|    6| 688883|2016-05-02 23:47:32|2014-06-28 00:18:16|      23|\n",
            "|    8| 900433|2015-08-11 02:08:47|2015-08-11 02:08:47|       0|\n",
            "|    8| 900433|2015-09-20 10:49:54|2015-08-11 02:08:47|       2|\n",
            "|    8| 659067|2016-02-10 11:55:25|2015-08-11 02:08:47|       7|\n",
            "|    8| 900433|2016-03-02 07:35:34|2015-08-11 02:08:47|       7|\n",
            "|    8| 900433|2016-04-18 05:46:42|2015-08-11 02:08:47|       9|\n",
            "|    8| 900433|2016-05-17 01:18:05|2015-08-11 02:08:47|      10|\n",
            "|    9|    243|2012-06-28 04:28:32|2012-06-28 04:28:32|       0|\n",
            "|    9|    243|2012-08-13 06:00:53|2012-06-28 04:28:32|       2|\n",
            "|    9|    243|2012-11-10 03:03:15|2012-06-28 04:28:32|       5|\n",
            "|    9|    243|2012-12-28 08:52:01|2012-06-28 04:28:32|       7|\n",
            "|    9|    243|2013-02-18 13:14:26|2012-06-28 04:28:32|       8|\n",
            "|    9|    243|2013-10-03 08:43:46|2012-06-28 04:28:32|      16|\n",
            "|    9| 755956|2015-05-19 04:58:47|2012-06-28 04:28:32|      36|\n",
            "|    9| 185494|2016-02-08 02:20:19|2012-06-28 04:28:32|      44|\n",
            "|    9| 367955|2016-08-24 01:57:40|2012-06-28 04:28:32|      51|\n",
            "|   10|    255|2012-11-25 09:20:39|2012-11-25 09:20:39|       0|\n",
            "|   10|     43|2012-12-23 11:08:45|2012-11-25 09:20:39|       1|\n",
            "|   10|     43|2012-12-31 12:44:12|2012-11-25 09:20:39|       2|\n",
            "|   10|     43|2013-01-01 02:26:16|2012-11-25 09:20:39|       2|\n",
            "|   10|    255|2013-01-14 08:18:43|2012-11-25 09:20:39|       2|\n",
            "|   10|     43|2013-03-03 12:47:10|2012-11-25 09:20:39|       4|\n",
            "|   10|    255|2013-03-11 04:38:51|2012-11-25 09:20:39|       4|\n",
            "|   10|  71056|2013-04-05 09:48:56|2012-11-25 09:20:39|       5|\n",
            "|   10|     13|2013-04-13 00:19:10|2012-11-25 09:20:39|       5|\n",
            "|   10| 133032|2013-07-25 23:42:09|2012-11-25 09:20:39|       9|\n",
            "+-----+-------+-------------------+-------------------+--------+\n",
            "only showing top 50 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7huqair5ICL",
        "colab_type": "code",
        "outputId": "644d5a1e-f503-4cdc-f852-e8505f7cf151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# since we only count the cumulative number of \"new\" friends met in each lifetime\n",
        "# get the first 'lifetime' value when each pair of users met\n",
        "dynamic_social.createOrReplaceTempView(\"table1\")\n",
        "num_friends = spark.sql(\"\"\"SELECT user1, user2, MIN(lifetime) AS lifetime\n",
        "                           FROM table1 \n",
        "                           GROUP BY user1, user2\n",
        "                           ORDER BY user1, MIN(lifetime)\"\"\")\n",
        "friend_list = num_friends\n",
        "num_friends.show(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-------+--------+\n",
            "|user1|  user2|lifetime|\n",
            "+-----+-------+--------+\n",
            "|    2|    220|       0|\n",
            "|    2|     43|      42|\n",
            "|    2| 191142|      47|\n",
            "|    3|     43|       0|\n",
            "|    3| 263437|       1|\n",
            "|    3|     52|       3|\n",
            "|    3|7854140|       4|\n",
            "|    3|1079020|       4|\n",
            "|    3|1204190|       4|\n",
            "|    3|2382556|       4|\n",
            "+-----+-------+--------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmrktfkq5Kw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use map reduce to create a dataframe with two columns: userid and lifetime that is consecutive from 0 to 12 months\n",
        "user_lifetime = dynamic_social.select(\"user1\", \"lifetime\").rdd\n",
        "user_lifetime = user_lifetime.flatMapValues(lambda value:range(0,13))\n",
        "# convert user_lifetime to a dataframe and rename the columns\n",
        "user_lifetime = user_lifetime.toDF([\"user1\", \"lifetime\"])\n",
        "user_lifetime.show(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l77iMjQX5QcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change the schema of user_lifetime, make two columns as integer type\n",
        "user_lifetime = user_lifetime.select(user_lifetime.user1.cast(IntegerType()), \n",
        "                                     user_lifetime.lifetime.cast(IntegerType()))\n",
        "user_lifetime.printSchema()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWpevddK5RAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_friends.createOrReplaceTempView(\"num_friends\")\n",
        "user_lifetime.createOrReplaceTempView(\"user_lifetime\")\n",
        "num_friends_one_year = spark.sql(\"\"\"\n",
        "                        SELECT user1, lifetime, COUNT(DISTINCT user2) AS num_friends\n",
        "                        FROM \n",
        "                          (SELECT user1, lifetime, user2 FROM num_friends\n",
        "                          UNION\n",
        "                          SELECT user1, lifetime, null AS user2 FROM user_lifetime) union_table\n",
        "                        WHERE lifetime <= 12\n",
        "                        GROUP BY user1, lifetime\n",
        "                        ORDER BY user1, lifetime\n",
        "                        \"\"\")\n",
        "num_friends_one_year.show(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fFkT-6x5TQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the cumulative number of friends in each lifetime month for each user\n",
        "num_fnd_window = Window.partitionBy(\"user1\").orderBy(\"lifetime\") \n",
        "num_friends_one_year = num_friends_one_year.withColumn(\"cum_num_friends\", \n",
        "                                                       sum(\"num_friends\").over(num_fnd_window)).sort(col(\"user1\"), \n",
        "                                                                                                     col(\"lifetime\"))\n",
        "num_friends_one_year.show(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2X-HKpo5YKD",
        "colab_type": "text"
      },
      "source": [
        "#### Number of friends of friends"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8h7I7C05VTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dynamic_social.createOrReplaceTempView(\"table1\")\n",
        "dynamic_social.createOrReplaceTempView(\"table2\")\n",
        "# self join the dynamic_social table, and select the first lifetime month that user met the friend of friend\n",
        "dynamic_social_self_join = spark.sql(\"\"\"SELECT table1.user1, table2.user2 as friend_of_friend,\n",
        "                                    MIN(table1.lifetime) AS lifetime\n",
        "                                    FROM table1\n",
        "                                    LEFT JOIN table2 ON table1.user2 = table2.user1\n",
        "                                    AND table1.user1 != table2.user2\n",
        "                                    AND table1.datetime >= table2.datetime\n",
        "                                    WHERE table1.lifetime <= 12\n",
        "                                    GROUP BY table1.user1, table2.user2\n",
        "                                    ORDER BY table1.user1, MIN(table1.lifetime)\"\"\")\n",
        "dynamic_social_self_join.show(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acSiLXkx5X3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dynamic_social_self_join.createOrReplaceTempView(\"table1\")\n",
        "friend_list.createOrReplaceTempView(\"table2\")\n",
        "# only consider the friend of friend whom user1 doesn't know. exclude the 1st degree friend\n",
        "num_friends_of_friends = spark.sql(\"\"\"SELECT table1.user1, friend_of_friend, table1.lifetime\n",
        "                                   FROM table1\n",
        "                                   LEFT JOIN table2 ON table1.user1 = table2.user1\n",
        "                                   AND table1.lifetime = table2.lifetime\n",
        "                                   AND table1.friend_of_friend = table2.user2\n",
        "                                   WHERE table2.user2 is null\n",
        "                                   OR friend_of_friend is null\n",
        "                                   ORDER BY table1.user1, table1.lifetime\n",
        "                                    \"\"\")\n",
        "friends_of_friends = num_friends_of_friends\n",
        "num_friends_of_friends.show(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PTBU4YqP_X_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_friends_of_friends.createOrReplaceTempView(\"num_friends_of_friends\")\n",
        "user_lifetime.createOrReplaceTempView(\"user_lifetime\")\n",
        "# make a consecutive 0-12 month lifetime\n",
        "num_friends_of_friends_one_year = spark.sql(\"\"\"\n",
        "                        SELECT user1, lifetime, COUNT(DISTINCT friend_of_friend) AS num_fnd_of_fnd\n",
        "                        FROM \n",
        "                          (SELECT user1, lifetime, friend_of_friend FROM num_friends_of_friends\n",
        "                          UNION\n",
        "                          SELECT user1, lifetime, null AS friend_of_friend FROM user_lifetime) union_table\n",
        "                        WHERE lifetime <= 12\n",
        "                        GROUP BY user1, lifetime\n",
        "                        ORDER BY user1, lifetime\n",
        "                        \"\"\")\n",
        "num_friends_of_friends_one_year.show(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTM5LaGPQGuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use window function to calculate the cumulative number of \"new\" friends of friends for each lifetime month\n",
        "num_fnd_fnd_window = Window.partitionBy(\"user1\").orderBy(\"lifetime\") \n",
        "num_friends_of_friends_one_year = num_friends_of_friends_one_year.withColumn(\"cum_num_fnd_of_fnd\", \n",
        "                                sum(\"num_fnd_of_fnd\").over(num_fnd_fnd_window)).sort(col(\"user1\"), \n",
        "                                                                                           col(\"lifetime\"))\n",
        "num_friends_of_friends_one_year.show(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB7h4iBc9-FO",
        "colab_type": "text"
      },
      "source": [
        "### ii) Cluster Coefficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wNZgnGccyqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_friends_one_year.createOrReplaceTempView(\"num_friends\")\n",
        "# calculate the number of possible vertices for each lifetime month\n",
        "num_vertices = spark.sql(\"\"\"SELECT user1, lifetime, cum_num_friends*(cum_num_friends-1)/2 AS num_vertices\n",
        "                            FROM num_friends\n",
        "                            ORDER BY user1, lifetime\"\"\")\n",
        "num_vertices.show(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yGlXqJi-KP1",
        "colab_type": "text"
      },
      "source": [
        "Or use rdd and map function to generate # possible vertices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-UnwaUwcy8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num_friends_rdd = num_friends_one_year.select(\"user1\", \"lifetime\", \"cum_num_friends\").rdd\n",
        "# num_vertices_rdd = num_friends_rdd.map(lambda row: num_vertices(row))\n",
        "\n",
        "# def num_vertices(row):\n",
        "#   vertice = row[2]*(row[2]-1)/2\n",
        "#   return(row[0], row[1], vertice)\n",
        "# num_vertices_df = num_vertices_rdd.toDF([\"user1\", \"lifetime\", \"num_vertices\"])\n",
        "# num_vertices_df = num_vertices_df.select(num_vertices_df.user1.cast(IntegerType()), \n",
        "#                                      num_vertices_df.lifetime.cast(IntegerType()),\n",
        "#                                      num_vertices_df.num_vertices.cast(IntegerType()))\n",
        "# num_vertices_df.printSchema()\n",
        "# num_vertices_df.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFAEa7-M-Igw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dynamic_social.createOrReplaceTempView(\"t1\")\n",
        "# only consider the date time when two users first transacted\n",
        "edges = spark.sql(\"\"\"SELECT user1, user2, MIN(datetime) AS datetime, MIN(lifetime) AS lifetime, MIN(start_date) AS start_date\n",
        "                      FROM t1 \n",
        "                      GROUP BY user1, user2\n",
        "                      ORDER BY user1, MIN(datetime)\"\"\")\n",
        "edges.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owe7xxUCcy_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edges.createOrReplaceTempView(\"t1\")\n",
        "edges.createOrReplaceTempView(\"t2\")\n",
        "edges.createOrReplaceTempView(\"t3\")\n",
        "# self join the edges table for three times, and make user2 of the table 3 equal to the user1 of the table1\n",
        "edges_3join = spark.sql(\"\"\"SELECT t1.user1 AS t1_user1, t1.user2 AS t1_user2, \n",
        "                        t1.start_date AS t1_start_date, t1.datetime AS t1_datetime, \n",
        "                        t2.user1 AS t2_user1, t2.user2 AS t2_user2, t2.datetime AS t2_datetime, \n",
        "                        t3.user1 AS t3_user1, t3.user2 AS t3_user2, t3.datetime AS t3_datetime\n",
        "                      FROM t1\n",
        "                      LEFT JOIN t2 ON t1.user2 = t2.user1\n",
        "                      AND t1.user1 != t2.user2\n",
        "                      LEFT JOIN t3 ON t2.user2 = t3.user1\n",
        "                      AND t2.user1 != t3.user2\n",
        "                      WHERE t1.user1 == t3.user2\n",
        "                      ORDER BY t1.user1, t1.lifetime\"\"\")\n",
        "edges_3join.show(20)\n",
        "# for table1 user1, each triangle will appear twice in the results table "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhWZLxYP-TTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edges_3join.createOrReplaceTempView(\"t1\")\n",
        "# calculate the date when the triangle formed by selecting the latest date of the transaction between three users\n",
        "# then calculate the lifetime for t1_user1 when the triangle formed \n",
        "edges_3join_tridate = spark.sql(\"\"\"\n",
        "                                SELECT t1_user1, t2_user1, t3_user1,\n",
        "                                ceil(DATEDIFF(GREATEST(t1_datetime, t2_datetime, t3_datetime), t1_start_date)/30)\n",
        "                                AS triangle_lifetime\n",
        "                                FROM t1\n",
        "                                \"\"\")\n",
        "edges_3join_tridate.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-w0CZ7k-WGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edges_3join_tridate.createOrReplaceTempView(\"t1\")\n",
        "# get the triangles of lifetime <= 12, and count the number of triangles group by each user and lifetime\n",
        "num_triangles = spark.sql(\"\"\"\n",
        "                                SELECT t1_user1 AS user1, triangle_lifetime AS lifetime,\n",
        "                                COUNT(*)/2 AS num_triangles\n",
        "                                FROM t1\n",
        "                                WHERE triangle_lifetime <= 12\n",
        "                                GROUP BY t1_user1, triangle_lifetime\n",
        "                                ORDER BY t1_user1, triangle_lifetime\n",
        "                                \"\"\")\n",
        "num_triangles.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBqMGhSB-bP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_triangles.createOrReplaceTempView(\"t1\")\n",
        "user_lifetime.createOrReplaceTempView(\"t2\")\n",
        "# get # triangles for consecutive 0-12 months\n",
        "num_triangles_one_year = spark.sql(\"\"\"\n",
        "                                SELECT user1, lifetime, SUM(num_triangles) AS num_triangles\n",
        "                                FROM(\n",
        "                                  SELECT user1, lifetime, num_triangles\n",
        "                                  FROM t1\n",
        "                                  UNION\n",
        "                                  SELECT user1, lifetime, 0 AS num_triangles\n",
        "                                  FROM t2) temp_table\n",
        "                                GROUP BY user1, lifetime\n",
        "                                ORDER BY user1, lifetime\n",
        "                                \"\"\")\n",
        "num_triangles_one_year.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alyWLCou-b4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the cumulative # triangles in each lifetime month for each user\n",
        "num_tri_window = Window.partitionBy(\"user1\").orderBy(\"lifetime\") \n",
        "num_triangles_one_year = num_triangles_one_year.withColumn(\"cum_num_triangles\", \n",
        "                                                       sum(\"num_triangles\").over(num_tri_window)).sort(col(\"user1\"), \n",
        "                                                                                                     col(\"lifetime\"))\n",
        "num_triangles_one_year.show(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIBSv_dN-gWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_triangles_one_year.createOrReplaceTempView(\"t1\")\n",
        "num_vertices.createOrReplaceTempView(\"t2\")\n",
        "\n",
        "cluster_coef = spark.sql(\"\"\"\n",
        "                          SELECT t1.user1, t1.lifetime, \n",
        "                          cum_num_triangles/NULLIF(num_vertices,0) AS cluster_coefficient\n",
        "                          FROM t1\n",
        "                          JOIN t2 ON t1.user1 = t2.user1\n",
        "                          AND t1.lifetime = t2.lifetime\n",
        "                          ORDER BY t1.user1, t1.lifetime\n",
        "                          \"\"\")\n",
        "cluster_coef.show(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q33wcbOQswTP",
        "colab_type": "text"
      },
      "source": [
        "### iii) PageRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "585pchCn-hBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transactions = inputdata.select(\"user1\", \"user2\")\n",
        "transactions_rdd = transactions.rdd\n",
        "transactions_tuples = transactions_rdd.map(tuple)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwvaQ3Zns7jI",
        "colab_type": "code",
        "outputId": "411c732f-46ae-46d1-c448-fcc2a86509af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "transactions_tuples.take(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1218774, 1528945), (5109483, 4782303)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYr4Am2is9HQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txn_tuples = transactions_tuples.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoDLH7Wqs_Cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G = nx.Graph()\n",
        "G.add_edges_from(txn_tuples)\n",
        "pr = nx.pagerank_scipy(G)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iEmiYHItReu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_list = [(key, pr[key]) for key in pr.keys()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_VTFJFetUHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "schema = StructType([\n",
        "    StructField(\"user1\", IntegerType(), True),\n",
        "    StructField(\"PageRank\", DoubleType(), True)\n",
        "])\n",
        "pr_df = spark.createDataFrame(pr_list, schema=schema)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IsL67-3tW1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr_df.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6Ft33fH6gC4",
        "colab_type": "text"
      },
      "source": [
        "# Part 3 Predictive Analytics with MLlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQGn8YjMei-P",
        "colab_type": "text"
      },
      "source": [
        "## Q7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEknL6gPemmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transaction_count = inputdata.select('user1', 'user2', 'datetime')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcvlRPpMepb0",
        "colab_type": "code",
        "outputId": "62a71941-164a-4316-c02f-d78726961be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "# use window function to get the date of the first transaction of each user1\n",
        "window = Window.partitionBy(\"user1\").orderBy(\"datetime\") \n",
        "transaction_count = transaction_count.withColumn(\"start_date\", min(\"datetime\").over(window))\n",
        "transaction_count.show(50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-------+-------------------+-------------------+\n",
            "|user1|  user2|           datetime|         start_date|\n",
            "+-----+-------+-------------------+-------------------+\n",
            "| 2866|  30588|2015-09-15 21:27:00|2015-09-15 21:27:00|\n",
            "| 6620|   6507|2012-04-16 21:32:43|2012-04-16 21:32:43|\n",
            "| 6620|   6606|2013-08-06 00:21:57|2012-04-16 21:32:43|\n",
            "|28170|  27438|2012-11-03 09:35:06|2012-11-03 09:35:06|\n",
            "|28759|  65628|2013-03-13 23:39:28|2013-03-13 23:39:28|\n",
            "|28759|  65628|2013-08-11 09:55:32|2013-03-13 23:39:28|\n",
            "|28759| 397277|2013-11-18 10:11:14|2013-03-13 23:39:28|\n",
            "|29894|  33385|2013-03-09 07:30:36|2013-03-09 07:30:36|\n",
            "|33602| 137025|2012-08-27 10:37:14|2012-08-27 10:37:14|\n",
            "|33602| 137025|2013-07-26 10:40:02|2012-08-27 10:37:14|\n",
            "|33602| 152043|2013-10-15 09:42:36|2012-08-27 10:37:14|\n",
            "|33602| 137025|2014-02-01 12:02:40|2012-08-27 10:37:14|\n",
            "|33602| 137025|2014-02-06 08:33:51|2012-08-27 10:37:14|\n",
            "|33602| 152043|2014-06-14 03:38:09|2012-08-27 10:37:14|\n",
            "|33602| 152043|2014-06-21 07:42:50|2012-08-27 10:37:14|\n",
            "|33602| 677386|2014-07-11 04:18:28|2012-08-27 10:37:14|\n",
            "|33602|4292661|2015-04-19 08:19:20|2012-08-27 10:37:14|\n",
            "|33602| 137025|2015-10-05 08:09:28|2012-08-27 10:37:14|\n",
            "|36525| 192549|2013-10-17 00:37:36|2013-10-17 00:37:36|\n",
            "|36525|  28192|2014-04-19 03:18:39|2013-10-17 00:37:36|\n",
            "|47283|  50233|2012-06-06 13:16:34|2012-06-06 13:16:34|\n",
            "|47283|  50233|2013-01-03 05:17:19|2012-06-06 13:16:34|\n",
            "|47283|  50233|2013-06-20 13:56:33|2012-06-06 13:16:34|\n",
            "|47283|  50233|2013-08-19 07:39:49|2012-06-06 13:16:34|\n",
            "|51415|  63807|2012-08-07 00:24:39|2012-08-07 00:24:39|\n",
            "|51415|  63807|2012-08-21 01:47:42|2012-08-07 00:24:39|\n",
            "|51415| 102073|2013-04-20 10:42:47|2012-08-07 00:24:39|\n",
            "|51415| 125984|2013-07-30 00:56:49|2012-08-07 00:24:39|\n",
            "|51415|  63807|2013-11-16 10:50:12|2012-08-07 00:24:39|\n",
            "|51415|  63807|2013-12-15 10:58:37|2012-08-07 00:24:39|\n",
            "|51415| 140312|2013-12-23 07:25:07|2012-08-07 00:24:39|\n",
            "|51415| 878958|2014-10-14 10:19:22|2012-08-07 00:24:39|\n",
            "|51415| 612699|2015-02-22 11:22:09|2012-08-07 00:24:39|\n",
            "|53963|4463238|2016-05-07 16:05:21|2016-05-07 16:05:21|\n",
            "|59990| 178013|2014-10-14 00:15:24|2014-10-14 00:15:24|\n",
            "|59990| 178013|2014-12-31 03:05:33|2014-10-14 00:15:24|\n",
            "|63087| 100977|2014-06-04 02:49:19|2014-06-04 02:49:19|\n",
            "|63087|  62361|2015-03-08 13:11:11|2014-06-04 02:49:19|\n",
            "|64423|  64350|2012-06-26 01:40:55|2012-06-26 01:40:55|\n",
            "|65408|  61673|2013-05-11 19:13:27|2013-05-11 19:13:27|\n",
            "|67492|  47721|2013-09-25 07:34:21|2013-09-25 07:34:21|\n",
            "|67492|  47721|2013-09-25 18:32:37|2013-09-25 07:34:21|\n",
            "|67492|  47721|2013-10-18 20:42:57|2013-09-25 07:34:21|\n",
            "|67492|  50153|2013-11-21 11:08:59|2013-09-25 07:34:21|\n",
            "|67492| 464001|2014-02-08 17:40:04|2013-09-25 07:34:21|\n",
            "|67492| 193638|2014-03-01 15:37:02|2013-09-25 07:34:21|\n",
            "|67492| 193638|2014-03-09 10:19:06|2013-09-25 07:34:21|\n",
            "|67492| 464001|2014-04-11 09:33:50|2013-09-25 07:34:21|\n",
            "|67492| 794064|2014-07-04 20:59:15|2013-09-25 07:34:21|\n",
            "|67492| 689895|2014-11-04 09:05:39|2013-09-25 07:34:21|\n",
            "+-----+-------+-------------------+-------------------+\n",
            "only showing top 50 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7H9ZjYXeqep",
        "colab_type": "code",
        "outputId": "2ba40c53-6491-46af-aab2-000980faff39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "transaction_count.createOrReplaceTempView(\"table7\")\n",
        "# calculate the lifetime month of the user1 for each line of transaction\n",
        "transaction_count = spark.sql(\"\"\"SELECT user1,COUNT(*) AS num_transaction\n",
        "FROM\n",
        "(SELECT user1, user2, datetime, start_date, \n",
        "ceil(datediff(datetime, start_date)/30) AS lifetime\n",
        "FROM table7) lifetime_table\n",
        "WHERE lifetime <= 12\n",
        "GROUP BY user1\n",
        "ORDER BY user1 \"\"\")\n",
        "transaction_count.show(50)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+---------------+\n",
            "|user1|num_transaction|\n",
            "+-----+---------------+\n",
            "|    2|              1|\n",
            "|    3|              6|\n",
            "|    4|              2|\n",
            "|   10|              7|\n",
            "|   11|              6|\n",
            "|   12|              4|\n",
            "|   13|              4|\n",
            "|   16|              3|\n",
            "|   19|              1|\n",
            "|   28|              1|\n",
            "|   34|              3|\n",
            "|   42|              3|\n",
            "|   43|             12|\n",
            "|   47|              1|\n",
            "|   52|              1|\n",
            "|   56|              1|\n",
            "|  112|              2|\n",
            "|  126|              2|\n",
            "|  129|              1|\n",
            "|  134|              2|\n",
            "|  149|              1|\n",
            "|  156|              1|\n",
            "|  159|              1|\n",
            "|  160|              1|\n",
            "|  164|              4|\n",
            "|  173|              2|\n",
            "|  192|              1|\n",
            "|  213|              4|\n",
            "|  225|              1|\n",
            "|  243|              5|\n",
            "|  244|              1|\n",
            "|  275|              2|\n",
            "|  312|              1|\n",
            "|  332|              1|\n",
            "|  347|              1|\n",
            "|  406|              3|\n",
            "|  420|              2|\n",
            "|  453|              5|\n",
            "|  611|              2|\n",
            "|  669|              2|\n",
            "|  712|              1|\n",
            "|  723|              1|\n",
            "|  747|              7|\n",
            "|  763|              2|\n",
            "|  767|              4|\n",
            "|  787|              1|\n",
            "|  794|              2|\n",
            "|  830|              1|\n",
            "|  859|              2|\n",
            "|  862|              1|\n",
            "+-----+---------------+\n",
            "only showing top 50 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgT3Ndm1extJ",
        "colab_type": "text"
      },
      "source": [
        "## Q8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA1cKtbpe0Zi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dynamic_social_8 = inputdata.select('user1', 'user2', 'datetime')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKmPdfjKe0cu",
        "colab_type": "code",
        "outputId": "8196a33c-e8af-48df-bf00-e2cf181e4ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "# use window function to get the date of the first transaction of each user1\n",
        "window = Window.partitionBy(\"user1\").orderBy(\"datetime\") \n",
        "dynamic_social_8 = dynamic_social_8.withColumn(\"start_date\", min(\"datetime\").over(window))\n",
        "dynamic_social_8.show(50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-------+-------------------+-------------------+\n",
            "|user1|  user2|           datetime|         start_date|\n",
            "+-----+-------+-------------------+-------------------+\n",
            "| 2866|  30588|2015-09-15 21:27:00|2015-09-15 21:27:00|\n",
            "| 6620|   6507|2012-04-16 21:32:43|2012-04-16 21:32:43|\n",
            "| 6620|   6606|2013-08-06 00:21:57|2012-04-16 21:32:43|\n",
            "|28170|  27438|2012-11-03 09:35:06|2012-11-03 09:35:06|\n",
            "|28759|  65628|2013-03-13 23:39:28|2013-03-13 23:39:28|\n",
            "|28759|  65628|2013-08-11 09:55:32|2013-03-13 23:39:28|\n",
            "|28759| 397277|2013-11-18 10:11:14|2013-03-13 23:39:28|\n",
            "|29894|  33385|2013-03-09 07:30:36|2013-03-09 07:30:36|\n",
            "|33602| 137025|2012-08-27 10:37:14|2012-08-27 10:37:14|\n",
            "|33602| 137025|2013-07-26 10:40:02|2012-08-27 10:37:14|\n",
            "|33602| 152043|2013-10-15 09:42:36|2012-08-27 10:37:14|\n",
            "|33602| 137025|2014-02-01 12:02:40|2012-08-27 10:37:14|\n",
            "|33602| 137025|2014-02-06 08:33:51|2012-08-27 10:37:14|\n",
            "|33602| 152043|2014-06-14 03:38:09|2012-08-27 10:37:14|\n",
            "|33602| 152043|2014-06-21 07:42:50|2012-08-27 10:37:14|\n",
            "|33602| 677386|2014-07-11 04:18:28|2012-08-27 10:37:14|\n",
            "|33602|4292661|2015-04-19 08:19:20|2012-08-27 10:37:14|\n",
            "|33602| 137025|2015-10-05 08:09:28|2012-08-27 10:37:14|\n",
            "|36525| 192549|2013-10-17 00:37:36|2013-10-17 00:37:36|\n",
            "|36525|  28192|2014-04-19 03:18:39|2013-10-17 00:37:36|\n",
            "|47283|  50233|2012-06-06 13:16:34|2012-06-06 13:16:34|\n",
            "|47283|  50233|2013-01-03 05:17:19|2012-06-06 13:16:34|\n",
            "|47283|  50233|2013-06-20 13:56:33|2012-06-06 13:16:34|\n",
            "|47283|  50233|2013-08-19 07:39:49|2012-06-06 13:16:34|\n",
            "|51415|  63807|2012-08-07 00:24:39|2012-08-07 00:24:39|\n",
            "|51415|  63807|2012-08-21 01:47:42|2012-08-07 00:24:39|\n",
            "|51415| 102073|2013-04-20 10:42:47|2012-08-07 00:24:39|\n",
            "|51415| 125984|2013-07-30 00:56:49|2012-08-07 00:24:39|\n",
            "|51415|  63807|2013-11-16 10:50:12|2012-08-07 00:24:39|\n",
            "|51415|  63807|2013-12-15 10:58:37|2012-08-07 00:24:39|\n",
            "|51415| 140312|2013-12-23 07:25:07|2012-08-07 00:24:39|\n",
            "|51415| 878958|2014-10-14 10:19:22|2012-08-07 00:24:39|\n",
            "|51415| 612699|2015-02-22 11:22:09|2012-08-07 00:24:39|\n",
            "|53963|4463238|2016-05-07 16:05:21|2016-05-07 16:05:21|\n",
            "|59990| 178013|2014-10-14 00:15:24|2014-10-14 00:15:24|\n",
            "|59990| 178013|2014-12-31 03:05:33|2014-10-14 00:15:24|\n",
            "|63087| 100977|2014-06-04 02:49:19|2014-06-04 02:49:19|\n",
            "|63087|  62361|2015-03-08 13:11:11|2014-06-04 02:49:19|\n",
            "|64423|  64350|2012-06-26 01:40:55|2012-06-26 01:40:55|\n",
            "|65408|  61673|2013-05-11 19:13:27|2013-05-11 19:13:27|\n",
            "|67492|  47721|2013-09-25 07:34:21|2013-09-25 07:34:21|\n",
            "|67492|  47721|2013-09-25 18:32:37|2013-09-25 07:34:21|\n",
            "|67492|  47721|2013-10-18 20:42:57|2013-09-25 07:34:21|\n",
            "|67492|  50153|2013-11-21 11:08:59|2013-09-25 07:34:21|\n",
            "|67492| 464001|2014-02-08 17:40:04|2013-09-25 07:34:21|\n",
            "|67492| 193638|2014-03-01 15:37:02|2013-09-25 07:34:21|\n",
            "|67492| 193638|2014-03-09 10:19:06|2013-09-25 07:34:21|\n",
            "|67492| 464001|2014-04-11 09:33:50|2013-09-25 07:34:21|\n",
            "|67492| 794064|2014-07-04 20:59:15|2013-09-25 07:34:21|\n",
            "|67492| 689895|2014-11-04 09:05:39|2013-09-25 07:34:21|\n",
            "+-----+-------+-------------------+-------------------+\n",
            "only showing top 50 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3G9O4DFe0he",
        "colab_type": "code",
        "outputId": "d4bb7753-ca89-473f-95f0-498ac2fa6bce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "dynamic_social_8.createOrReplaceTempView(\"table1\")\n",
        "# calculate the lifetime month of the user1 for each line of transaction\n",
        "dynamic_social_8 = spark.sql(\"\"\"SELECT user1, user2, datetime, start_date, \n",
        "                           CEIL(DATEDIFF(datetime, start_date)/30) AS lifetime,\n",
        "                           CEIL(DATEDIFF(datetime, start_date)/30) * 30 AS lifetime_days,\n",
        "                           DATEDIFF(datetime, start_date) AS days\n",
        "                           FROM table1 \n",
        "                           ORDER BY user1, datetime\"\"\")\n",
        "dynamic_social_8.show(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-------+-------------------+-------------------+--------+-------------+----+\n",
            "|user1|  user2|           datetime|         start_date|lifetime|lifetime_days|days|\n",
            "+-----+-------+-------------------+-------------------+--------+-------------+----+\n",
            "|    2|    220|2012-11-23 06:03:42|2012-11-23 06:03:42|       0|            0|   0|\n",
            "|    3|     52|2016-09-22 15:30:09|2016-09-22 15:30:09|       0|            0|   0|\n",
            "|    3|2382556|2016-10-06 10:49:45|2016-09-22 15:30:09|       1|           30|  14|\n",
            "|    3|2382556|2016-10-07 08:50:23|2016-09-22 15:30:09|       1|           30|  15|\n",
            "|    3|1079020|2016-10-07 23:37:56|2016-09-22 15:30:09|       1|           30|  15|\n",
            "|    3|1204190|2016-10-09 01:56:24|2016-09-22 15:30:09|       1|           30|  17|\n",
            "|    3|7854140|2016-10-09 03:36:13|2016-09-22 15:30:09|       1|           30|  17|\n",
            "|    4| 122744|2012-12-03 03:35:53|2012-12-03 03:35:53|       0|            0|   0|\n",
            "|    4| 125527|2012-12-15 05:51:12|2012-12-03 03:35:53|       1|           30|  12|\n",
            "|    4| 968271|2014-02-04 06:51:33|2012-12-03 03:35:53|      15|          450| 428|\n",
            "+-----+-------+-------------------+-------------------+--------+-------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArMHS0meO4bF",
        "colab_type": "code",
        "outputId": "35eccc7c-ab84-40ed-c729-a5f8cc526303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dynamic_social_8.createOrReplaceTempView(\"t1\")\n",
        "# calculate the lifetime month of the user1 for each line of transaction\n",
        "df_rfmodel = spark.sql(\"\"\"SELECT user1, lifetime, lifetime_days, max(days) AS latest_txn, COUNT(*) AS num_txn \n",
        "                           FROM t1\n",
        "                           WHERE lifetime <= 12\n",
        "                           GROUP BY user1, lifetime,lifetime_days\n",
        "                           ORDER BY user1, lifetime\"\"\")\n",
        "df_rfmodel.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------+-------------+----------+-------+\n",
            "|user1|lifetime|lifetime_days|latest_txn|num_txn|\n",
            "+-----+--------+-------------+----------+-------+\n",
            "|    2|       0|            0|         0|      1|\n",
            "|    3|       0|            0|         0|      1|\n",
            "|    3|       1|           30|        17|      5|\n",
            "|    4|       0|            0|         0|      1|\n",
            "|    4|       1|           30|        12|      1|\n",
            "+-----+--------+-------------+----------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnD06WR8O4Xs",
        "colab_type": "code",
        "outputId": "816359ab-2324-480d-8e2c-fd089a4fff6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# use map reduce to create a dataframe with two columns: userid and lifetime that is consecutive from 0 to 12 months\n",
        "user_lifetime_8 = dynamic_social_8.select(\"user1\", \"lifetime\").rdd\n",
        "user_lifetime_8 = user_lifetime_8.flatMapValues(lambda value:range(0,13))\n",
        "# convert user_lifetime to a dataframe and rename the columns\n",
        "user_lifetime_8 = user_lifetime_8.toDF([\"user1\", \"lifetime\"])\n",
        "user_lifetime_8.show(15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------+\n",
            "|user1|lifetime|\n",
            "+-----+--------+\n",
            "|    2|       0|\n",
            "|    2|       1|\n",
            "|    2|       2|\n",
            "|    2|       3|\n",
            "|    2|       4|\n",
            "|    2|       5|\n",
            "|    2|       6|\n",
            "|    2|       7|\n",
            "|    2|       8|\n",
            "|    2|       9|\n",
            "|    2|      10|\n",
            "|    2|      11|\n",
            "|    2|      12|\n",
            "|    3|       0|\n",
            "|    3|       1|\n",
            "+-----+--------+\n",
            "only showing top 15 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH2i9X3FcKHk",
        "colab_type": "code",
        "outputId": "4a56e0e6-49c3-4226-d5f6-b01a31f70f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# change the schema of user_lifetime, make two columns as integer type\n",
        "user_lifetime_8 = user_lifetime_8.select(user_lifetime_8.user1.cast(IntegerType()), \n",
        "                                     user_lifetime_8.lifetime.cast(IntegerType()))\n",
        "user_lifetime_8.printSchema()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- user1: integer (nullable = true)\n",
            " |-- lifetime: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7H25xnAcH8y",
        "colab_type": "code",
        "outputId": "7ff65634-e11a-4c4f-80da-51171f99d20b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_rfmodel.createOrReplaceTempView(\"df_rfmodel\")\n",
        "user_lifetime_8.createOrReplaceTempView(\"user_lifetime\")\n",
        "df_rfmodel_full = spark.sql(\"\"\"SELECT user1, lifetime, lifetime_days, MAX(latest_txn) AS latest_txn, \n",
        "                        MAX(num_txn) AS num_txn\n",
        "                        FROM\n",
        "                          (SELECT user1, lifetime, lifetime_days, latest_txn, num_txn FROM df_rfmodel\n",
        "                          UNION\n",
        "                          SELECT user1, lifetime, lifetime * 30 AS lifetime_days, null AS latest_txn, null AS num_txn FROM user_lifetime) union_table\n",
        "                        GROUP BY user1, lifetime, lifetime_days\n",
        "                        ORDER BY user1, lifetime \"\"\")\n",
        "df_rfmodel_full.show(5)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------+-------------+----------+-------+\n",
            "|user1|lifetime|lifetime_days|latest_txn|num_txn|\n",
            "+-----+--------+-------------+----------+-------+\n",
            "|    2|       0|            0|         0|      1|\n",
            "|    2|       1|           30|      null|   null|\n",
            "|    2|       2|           60|      null|   null|\n",
            "|    2|       3|           90|      null|   null|\n",
            "|    2|       4|          120|      null|   null|\n",
            "+-----+--------+-------------+----------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18H4NryacTvh",
        "colab_type": "code",
        "outputId": "1b4d4ee4-9a1f-4bde-afa5-d1cae12d3d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# calculate frequency and recency\n",
        "# frequency: how often a user uses Venmo in a month. It is standardized and equals to (number of transactions/30)\n",
        "# recency: the last time a user was active\n",
        "    #if a user has used Venmo twice during her first month in Venmo with the second time being on day x, \n",
        "    #then her recency in month 1 is ‚Äú30-x‚Äù\n",
        "df_rfmodel_full.createOrReplaceTempView(\"df_rfmodel_full\")\n",
        "rf_model = spark.sql(\"SELECT user1, lifetime, lifetime_days, \\\n",
        "                IFNULL(((sum(num_txn) OVER (PARTITION BY user1 ORDER BY lifetime))/lifetime_days, 0) AS frequency, \\\n",
        "                (lifetime_days - MAX(latest_txn) \\\n",
        "                    OVER(PARTITION BY user1 \\\n",
        "                         ORDER BY lifetime ASC)) AS recency \\\n",
        "              FROM df_rfmodel_full \\\n",
        "              ORDER BY user1, lifetime\")\n",
        "\n",
        "rf_model.createOrReplaceTempView(\"rf_model\")\n",
        "rf_model.show(24)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------+-------------+----------+-------+-------------------+-------+\n",
            "|user1|lifetime|lifetime_days|latest_txn|num_txn|          frequency|recency|\n",
            "+-----+--------+-------------+----------+-------+-------------------+-------+\n",
            "|    2|       0|            0|         0|      1|0.03333333333333333|      0|\n",
            "|    2|       1|           30|      null|   null|                0.0|     30|\n",
            "|    2|       2|           60|      null|   null|                0.0|     60|\n",
            "|    2|       3|           90|      null|   null|                0.0|     90|\n",
            "|    2|       4|          120|      null|   null|                0.0|    120|\n",
            "|    2|       5|          150|      null|   null|                0.0|    150|\n",
            "|    2|       6|          180|      null|   null|                0.0|    180|\n",
            "|    2|       7|          210|      null|   null|                0.0|    210|\n",
            "|    2|       8|          240|      null|   null|                0.0|    240|\n",
            "|    2|       9|          270|      null|   null|                0.0|    270|\n",
            "|    2|      10|          300|      null|   null|                0.0|    300|\n",
            "|    2|      11|          330|      null|   null|                0.0|    330|\n",
            "|    2|      12|          360|      null|   null|                0.0|    360|\n",
            "|    3|       0|            0|         0|      1|0.03333333333333333|      0|\n",
            "|    3|       1|           30|        17|      5|0.16666666666666666|     13|\n",
            "|    3|       2|           60|      null|   null|                0.0|     43|\n",
            "|    3|       3|           90|      null|   null|                0.0|     73|\n",
            "|    3|       4|          120|      null|   null|                0.0|    103|\n",
            "|    3|       5|          150|      null|   null|                0.0|    133|\n",
            "|    3|       6|          180|      null|   null|                0.0|    163|\n",
            "|    3|       7|          210|      null|   null|                0.0|    193|\n",
            "|    3|       8|          240|      null|   null|                0.0|    223|\n",
            "|    3|       9|          270|      null|   null|                0.0|    253|\n",
            "|    3|      10|          300|      null|   null|                0.0|    283|\n",
            "+-----+--------+-------------+----------+-------+-------------------+-------+\n",
            "only showing top 24 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGtP56x7C-CD",
        "colab_type": "text"
      },
      "source": [
        "## Q9 \n",
        "For each user‚Äôs lifetime point, regress recency and frequency on Y. Plot the MSE for each lifetime point. In other words, your x-axis will be lifetime in months (0-12), and your yaxis will be the MSE. (Hint: Don‚Äôt forget to split your data into train and test sets)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V73L0nSVC_qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transaction_count.createOrReplaceTempView(\"transaction_count_table\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxQZhaTVDILE",
        "colab_type": "code",
        "outputId": "bb065527-677c-4576-d152-138cb3612e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# join tables to combine user lifetime, frequency, recency and number of total transactions (y)\n",
        "regression9_input = spark.sql(\"\"\"SELECT user1, lifetime, frequency, recency, num_transaction\n",
        "                  FROM rf_model JOIN transaction_count_table USING (user1)\n",
        "                  ORDER BY user1, lifetime\"\"\")\n",
        "regression9_input.createOrReplaceTempView(\"regression9_input\")\n",
        "regression9_input.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------+-------------------+-------+---------------+\n",
            "|user1|lifetime|          frequency|recency|num_transaction|\n",
            "+-----+--------+-------------------+-------+---------------+\n",
            "|    2|       0|0.03333333333333333|      0|              1|\n",
            "|    2|       1|                0.0|     30|              1|\n",
            "|    2|       2|                0.0|     60|              1|\n",
            "|    2|       3|                0.0|     90|              1|\n",
            "|    2|       4|                0.0|    120|              1|\n",
            "|    2|       5|                0.0|    150|              1|\n",
            "|    2|       6|                0.0|    180|              1|\n",
            "|    2|       7|                0.0|    210|              1|\n",
            "|    2|       8|                0.0|    240|              1|\n",
            "|    2|       9|                0.0|    270|              1|\n",
            "|    2|      10|                0.0|    300|              1|\n",
            "|    2|      11|                0.0|    330|              1|\n",
            "|    2|      12|                0.0|    360|              1|\n",
            "|    3|       0|0.03333333333333333|      0|              6|\n",
            "|    3|       1|0.16666666666666666|     13|              6|\n",
            "|    3|       2|                0.0|     43|              6|\n",
            "|    3|       3|                0.0|     73|              6|\n",
            "|    3|       4|                0.0|    103|              6|\n",
            "|    3|       5|                0.0|    133|              6|\n",
            "|    3|       6|                0.0|    163|              6|\n",
            "+-----+--------+-------------------+-------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVyPeVlADIQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regression9_input.createOrReplaceTempView(\"regression9_input\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPVhdVFSDIWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regression9_input_lifetime0 = spark.sql(\"select * from regression9_input where lifetime=0 \")\n",
        "regression9_input_lifetime1 = spark.sql(\"select * from regression9_input where lifetime=1 \")\n",
        "regression9_input_lifetime2 = spark.sql(\"select * from regression9_input where lifetime=2 \")\n",
        "regression9_input_lifetime3 = spark.sql(\"select * from regression9_input where lifetime=3 \")\n",
        "regression9_input_lifetime4 = spark.sql(\"select * from regression9_input where lifetime=4 \")\n",
        "regression9_input_lifetime5 = spark.sql(\"select * from regression9_input where lifetime=5 \")\n",
        "regression9_input_lifetime6 = spark.sql(\"select * from regression9_input where lifetime=6 \")\n",
        "regression9_input_lifetime7 = spark.sql(\"select * from regression9_input where lifetime=7 \")\n",
        "regression9_input_lifetime8 = spark.sql(\"select * from regression9_input where lifetime=8 \")\n",
        "regression9_input_lifetime9 = spark.sql(\"select * from regression9_input where lifetime=9 \")\n",
        "regression9_input_lifetime10 = spark.sql(\"select * from regression9_input where lifetime=10 \")\n",
        "regression9_input_lifetime11 = spark.sql(\"select * from regression9_input where lifetime=11 \")\n",
        "regression9_input_lifetime12 = spark.sql(\"select * from regression9_input where lifetime=12 \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU4p6qxfDIb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lifetimeMSE(inputdata):\n",
        "    Assembler = VectorAssembler(inputCols = ['frequency', 'recency'], \n",
        "                                outputCol ='features')\n",
        "    outputdata = Assembler.transform(inputdata)\n",
        "    model_df = outputdata.select('features','num_transaction')\n",
        "    train_df, test_df = model_df.randomSplit([0.7, 0.3], seed=1)\n",
        "    lin_reg = LinearRegression(labelCol ='num_transaction', featuresCol='features')\n",
        "    lr_model = lin_reg.fit(train_df)\n",
        "    test_results = lr_model.evaluate(test_df)\n",
        "    r_mse = test_results.rootMeanSquaredError\n",
        "    mse = r_mse**2\n",
        "    return mse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUT_7_ezq89H",
        "colab_type": "code",
        "outputId": "11cacbc7-018a-494a-f201-8e37e4356282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MSE_lifetime0 = lifetimeMSE(regression9_input_lifetime0)\n",
        "print(MSE_lifetime0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.805281950545989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvTMYMmmDIhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MSE_9 = []\n",
        "MSE_9.extend([MSE_lifetime0, MSE_lifetime1, MSE_lifetime2, MSE_lifetime3, MSE_lifetime4, MSE_lifetime5, MSE_lifetime6, \n",
        "            MSE_lifetime7, MSE_lifetime8, MSE_lifetime9, MSE_lifetime10, MSE_lifetime11, MSE_lifetime12])\n",
        "MSE_9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toM9PmU2DIap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Lifetime_x = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
        "plt.plot(Lifetime_x, MSE_9, 'ro--', linewidth=2, markersize=8) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yXXA1oIR3tk",
        "colab_type": "text"
      },
      "source": [
        "## Q10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUMa1AKHameC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dynamic_profile = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/dynamic_profile.parquet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riDmiBSJlIti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine the dynamic spending profile table with the frequency and recency table\n",
        "dynamic_profile.createOrReplaceTempView(\"dynamic_profile\")\n",
        "regression9_input.createOrReplaceTempView(\"regression9_input\")\n",
        "\n",
        "full_dynamic = spark.sql('''\n",
        "                                SELECT user1, lifetime, F.max(frequency) as frequency, \\\n",
        "                                F.max(recency) as recency, F.max(ifnull(people,0)) as people, \\\n",
        "                                F.max(ifnull(food,0)) as food, F.max(ifnull(activity,0)) as activity, \\\n",
        "                                F.max(ifnull(event,0)) as event, F.max(ifnull(travel,0)) as travel, \\\n",
        "                                F.max(ifnull(cash,0)) as cash, F.max(ifnull(utility,0)) as utility, \\\n",
        "                                F.max(ifnull(trasportation,0)) as trasportation, \\\n",
        "                                F.max(ifnull(illegal_sarcasm,0)) as illegal_sarcasm, \\\n",
        "                                F.max(ifnull(not_classified,0)) as not_classified \\\n",
        "                                FROM\n",
        "                                (SELECT *, null as frequency, null as recency\n",
        "                                 FROM dynamic_profile\n",
        "                                 UNION\n",
        "                                 SELECT user1,lifetime,null,null,null,null,null, \\\n",
        "                                 null,null,null,null,null, frequency, recency \n",
        "                                 FROM regression9_input\n",
        "                                )\n",
        "                                GROUP BY user1, lifetime\n",
        "                                ORDER BY user1, lifetime\n",
        "                                \n",
        "                                ''')\n",
        "full_dynamic.createOrReplaceTempView(\"regression10_input\")\n",
        "#full_dynamic.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odU_yJxZlKlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generating the regression input table\n",
        "full_dynamic.createOrReplaceTempView(\"full_dynamic\")\n",
        "transaction_count.createOrReplaceTempView(\"transaction_count\")\n",
        "regression10_input = spark.sql('''\n",
        "                                SELECT * \n",
        "                                FROM full_dynamic \n",
        "                                JOIN transaction_count\n",
        "                                USING (user1) \n",
        "                                ORDER BY user1, lifetime\n",
        "                                ''')\n",
        "\n",
        "regression10_input.createOrReplaceTempView(\"df_dynamic_input\")\n",
        "regression10_input.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDFGAZcsbMtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regression10_input.createOrReplaceTempView(\"regression10_input\")\n",
        "dynamic_input_time0 = spark.sql(\"select * from regression10_input where lifetime=0 \")\n",
        "dynamic_input_time1 = spark.sql(\"select * from regression10_input where lifetime=1 \")\n",
        "dynamic_input_time2 = spark.sql(\"select * from regression10_input where lifetime=2 \")\n",
        "dynamic_input_time3 = spark.sql(\"select * from regression10_input where lifetime=3 \")\n",
        "dynamic_input_time4 = spark.sql(\"select * from regression10_input where lifetime=4 \")\n",
        "dynamic_input_time5 = spark.sql(\"select * from regression10_input where lifetime=5 \")\n",
        "dynamic_input_time6 = spark.sql(\"select * from regression10_input where lifetime=6 \")\n",
        "dynamic_input_time7 = spark.sql(\"select * from regression10_input where lifetime=7 \")\n",
        "dynamic_input_time8 = spark.sql(\"select * from regression10_input where lifetime=8 \")\n",
        "dynamic_input_time9 = spark.sql(\"select * from regression10_input where lifetime=9 \")\n",
        "dynamic_input_time10 = spark.sql(\"select * from regression10_input where lifetime=10 \")\n",
        "dynamic_input_time11 = spark.sql(\"select * from regression10_input where lifetime=11 \")\n",
        "dynamic_input_time12 = spark.sql(\"select * from regression10_input where lifetime=12 \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QexUJj18bNqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dynamicMSE(inputdata):\n",
        "    Assembler = VectorAssembler(inputCols = ['lifetime', 'frequency', 'recency',\n",
        "                            'people', 'food', 'activity', 'event', 'travel', 'cash',\n",
        "                            'utility', 'transportation', 'illegal_sarcasm', 'not_classified'], \n",
        "                                outputCol ='features')\n",
        "    output = Assembler.transform(inputdata)\n",
        "    finalData = output.select('features','num_transaction')\n",
        "    trainData, testData = finalData.randomSplit([0.7, 0.3], seed=1)\n",
        "    lrModel = LinearRegression(labelCol ='num_transaction', featuresCol='features')\n",
        "    lrEstimator = lrModel.fit(trainData)\n",
        "    testResults = lrEstimator.evaluate(testData)\n",
        "    rmse = testResults.rootMeanSquaredError\n",
        "    mse = rmse**2\n",
        "    return mse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOQ1Mg3Hbfzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dynamic_MSE_time0 = dynamicMSE(dynamic_input_time0)\n",
        "print(\"MSE_time0: \", dynamic_MSE_time0)\n",
        "dynamic_MSE_time1 = dynamicMSE(dynamic_input_time1)\n",
        "print(\"MSE_time1: \", dynamic_MSE_time1)\n",
        "dynamic_MSE_time2 = dynamicMSE(dynamic_input_time2)\n",
        "print(\"MSE_time2: \", dynamic_MSE_time2)\n",
        "dynamic_MSE_time3 = dynamicMSE(dynamic_input_time3)\n",
        "print(\"MSE_time3: \", dynamic_MSE_time3)\n",
        "dynamic_MSE_time4 = dynamicMSE(dynamic_input_time4)\n",
        "print(\"MSE_time4: \", dynamic_MSE_time4)\n",
        "dynamic_MSE_time5 = dynamicMSE(dynamic_input_time5)\n",
        "print(\"MSE_time5: \", dynamic_MSE_time5)\n",
        "dynamic_MSE_time6 = dynamicMSE(dynamic_input_time6)\n",
        "print(\"MSE_time6: \", dynamic_MSE_time6)\n",
        "dynamic_MSE_time7 = dynamicMSE(dynamic_input_time7)\n",
        "print(\"MSE_time7: \", dynamic_MSE_time7)\n",
        "dynamic_MSE_time8 = dynamicMSE(dynamic_input_time8)\n",
        "print(\"MSE_time8: \", dynamic_MSE_time8)\n",
        "dynamic_MSE_time9 = dynamicMSE(dynamic_input_time9)\n",
        "print(\"MSE_time9: \", dynamic_MSE_time9)\n",
        "dynamic_MSE_time10 = dynamicMSE(dynamic_input_time10)\n",
        "print(\"MSE_time10: \", dynamic_MSE_time10)\n",
        "dynamic_MSE_time11 = dynamicMSE(dynamic_input_time11)\n",
        "print(\"MSE_time11: \", dynamic_MSE_time11)\n",
        "dynamic_MSE_time12 = dynamicMSE(dynamic_input_time12)\n",
        "print(\"MSE_time12: \", dynamic_MSE_time12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELHsooygcBza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the results\n",
        "MSE_11 = []\n",
        "MSE_11.extend([dynamic_MSE_time0, dynamic_MSE_time1, dynamic_MSE_time2, dynamic_MSE_time3, dynamic_MSE_time4, dynamic_MSE_time5, dynamic_MSE_time6, \n",
        "            dynamic_MSE_time7, dynamic_MSE_time8, dynamic_MSE_time9, dynamic_MSE_time10, dynamic_MSE_time11, dynamic_MSE_time12])\n",
        "\n",
        "Lifetime_x = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
        "plt.plot(Lifetime_x, MSE_11, 'go--', linewidth=2, markersize=8) \n",
        "\n",
        "plt.xlabel('lifetime')\n",
        "plt.ylabel('MSE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFP90qWDK4S1",
        "colab_type": "text"
      },
      "source": [
        "## Q11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCoFmggsR-9t",
        "colab_type": "text"
      },
      "source": [
        "### We first run the # friends, # fof, # triangles and page rank. The following code is from the previous sections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5S2V8ovR8CD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dynamic_social_11 = inputdata.select('user1', 'user2', 'datetime').union(inputdata.select('user2', 'user1', 'datetime'))\n",
        "# use window function to get the date of the first transaction of each user1\n",
        "from pyspark.sql import Window\n",
        "window = Window.partitionBy(\"user1\").orderBy(\"datetime\") \n",
        "from pyspark.sql.functions import min\n",
        "dynamic_social_11 = dynamic_social_11.withColumn(\"start_date\", min(\"datetime\").over(window))\n",
        "# dynamic_social_11.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2TLAfXgSFSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dynamic_social_11.createOrReplaceTempView(\"table1\")\n",
        "# calculate the lifetime month of the user1 for each line of transaction\n",
        "dynamic_social_11 = spark.sql(\"\"\"SELECT user1, user2, datetime, start_date, \n",
        "                           ceil(datediff(datetime, start_date)/30) AS lifetime\n",
        "                           FROM table1 \n",
        "                           ORDER BY user1, datetime\"\"\")\n",
        "# dynamic_social_11.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CofywfkSSH10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# since we only count the cumulative number of \"new\" friends met in each lifetime\n",
        "# get the first 'lifetime' value when each pair of users met\n",
        "dynamic_social_11.createOrReplaceTempView(\"table1\")\n",
        "num_friends = spark.sql(\"\"\"SELECT user1, user2, MIN(lifetime) AS lifetime\n",
        "                           FROM table1 \n",
        "                           GROUP BY user1, user2\n",
        "                           ORDER BY user1, MIN(lifetime)\"\"\")\n",
        "friend_list = num_friends\n",
        "# num_friends.show(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73YFxBeHSKKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use map reduce to create a dataframe with two columns: userid and lifetime that is consecutive from 0 to 12 months\n",
        "user_lifetime = dynamic_social_11.select(\"user1\", \"lifetime\").rdd\n",
        "user_lifetime = user_lifetime.flatMapValues(lambda value: range(0,13))\n",
        "# convert user_lifetime to a dataframe and rename the columns\n",
        "user_lifetime = user_lifetime.toDF([\"user1\", \"lifetime\"])\n",
        "# user_lifetime.show(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYDEeDZPSMJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change the schema of user_lifetime, make two columns as integer type\n",
        "from pyspark.sql.types import IntegerType\n",
        "user_lifetime = user_lifetime.select(user_lifetime.user1.cast(IntegerType()), \n",
        "                                     user_lifetime.lifetime.cast(IntegerType()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auTL6EP9SNzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_friends.createOrReplaceTempView(\"num_friends\")\n",
        "user_lifetime.createOrReplaceTempView(\"user_lifetime\")\n",
        "num_friends_one_year = spark.sql(\"\"\"\n",
        "                        SELECT user1, lifetime, COUNT(DISTINCT user2) AS num_friends\n",
        "                        FROM \n",
        "                          (SELECT user1, lifetime, user2 FROM num_friends\n",
        "                          UNION\n",
        "                          SELECT user1, lifetime, null AS user2 FROM user_lifetime) union_table\n",
        "                        WHERE lifetime <= 12\n",
        "                        GROUP BY user1, lifetime\n",
        "                        ORDER BY user1, lifetime\n",
        "                        \"\"\")\n",
        "# num_friends_one_year.show(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZf4oIdtSPip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the cumulative number of friends in each lifetime month for each user\n",
        "num_fnd_window = Window.partitionBy(\"user1\").orderBy(\"lifetime\") \n",
        "from pyspark.sql.functions import sum, col\n",
        "num_friends_one_year = num_friends_one_year.withColumn(\"cum_num_friends\", \n",
        "                                                       sum(\"num_friends\").over(num_fnd_window)).sort(col(\"user1\"), \n",
        "                                                                                                     col(\"lifetime\"))\n",
        "# num_friends_one_year.show(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lOaXwQgSRdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dynamic_social_11.createOrReplaceTempView(\"table1\")\n",
        "dynamic_social_11.createOrReplaceTempView(\"table2\")\n",
        "# self join the dynamic_social table, and select the first lifetime month that user met the friend of friend\n",
        "dynamic_social_self_join_11 = spark.sql(\"\"\"SELECT table1.user1, table2.user2 as friend_of_friend,\n",
        "                                    MIN(table1.lifetime) AS lifetime\n",
        "                                    FROM table1\n",
        "                                    LEFT JOIN table2 ON table1.user2 = table2.user1\n",
        "                                    AND table1.user1 != table2.user2\n",
        "                                    AND table1.datetime >= table2.datetime\n",
        "                                    WHERE table1.lifetime <= 12\n",
        "                                    GROUP BY table1.user1, table2.user2\n",
        "                                    ORDER BY table1.user1, MIN(table1.lifetime)\"\"\")\n",
        "# dynamic_social_self_join_11.show(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sojjQHo4STZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dynamic_social_self_join_11.createOrReplaceTempView(\"table1\")\n",
        "friend_list.createOrReplaceTempView(\"table2\")\n",
        "# only consider the friend of friend whom user1 doesn't know. exclude the 1st degree friend\n",
        "num_friends_of_friends = spark.sql(\"\"\"SELECT table1.user1, friend_of_friend, table1.lifetime\n",
        "                                   FROM table1\n",
        "                                   LEFT JOIN table2 ON table1.user1 = table2.user1\n",
        "                                   AND table1.lifetime = table2.lifetime\n",
        "                                   AND table1.friend_of_friend = table2.user2\n",
        "                                   WHERE table2.user2 is null\n",
        "                                   OR friend_of_friend is null\n",
        "                                   ORDER BY table1.user1, table1.lifetime\n",
        "                                    \"\"\")\n",
        "friends_of_friends = num_friends_of_friends\n",
        "# num_friends_of_friends.show(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEevwYKPSVFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_friends_of_friends.createOrReplaceTempView(\"num_friends_of_friends\")\n",
        "user_lifetime.createOrReplaceTempView(\"user_lifetime\")\n",
        "num_friends_of_friends_one_year = spark.sql(\"\"\"\n",
        "                        SELECT user1, lifetime, COUNT(DISTINCT friend_of_friend) AS num_fnd_of_fnd\n",
        "                        FROM \n",
        "                          (SELECT user1, lifetime, friend_of_friend FROM num_friends_of_friends\n",
        "                          UNION\n",
        "                          SELECT user1, lifetime, null AS friend_of_friend FROM user_lifetime) union_table\n",
        "                        WHERE lifetime <= 12\n",
        "                        GROUP BY user1, lifetime\n",
        "                        ORDER BY user1, lifetime\n",
        "                        \"\"\")\n",
        "# num_friends_of_friends_one_year.show(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YcNrvOsSWy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# use window function to calculate the cumulative number of \"new\" friends of friends for each lifetime month\n",
        "num_fnd_fnd_window = Window.partitionBy(\"user1\").orderBy(\"lifetime\") \n",
        "from pyspark.sql.functions import sum\n",
        "num_friends_of_friends_one_year = num_friends_of_friends_one_year.withColumn(\"cum_num_fnd_of_fnd\", \n",
        "                                sum(\"num_fnd_of_fnd\").over(num_fnd_fnd_window)).sort(col(\"user1\"), \n",
        "                                                                                           col(\"lifetime\"))\n",
        "# num_friends_of_friends_one_year.show(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj4ZddP7SZ01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dynamic_social_11.createOrReplaceTempView(\"t1\")\n",
        "# only consider the date time when two users first transacted\n",
        "edges = spark.sql(\"\"\"SELECT user1, user2, MIN(datetime) AS datetime, MIN(lifetime) AS lifetime, MIN(start_date) AS start_date\n",
        "                      FROM t1 \n",
        "                      GROUP BY user1, user2\n",
        "                      ORDER BY user1, MIN(datetime)\"\"\")\n",
        "# edges.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT0Mr5ikSawC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edges.createOrReplaceTempView(\"t1\")\n",
        "edges.createOrReplaceTempView(\"t2\")\n",
        "edges.createOrReplaceTempView(\"t3\")\n",
        "# self join the edges table for three times, and make user2 of the table 3 equal to the user1 of the table1\n",
        "edges_3join = spark.sql(\"\"\"SELECT t1.user1 AS t1_user1, t1.user2 AS t1_user2, \n",
        "                        t1.start_date AS t1_start_date, t1.datetime AS t1_datetime, \n",
        "                        t2.user1 AS t2_user1, t2.user2 AS t2_user2, t2.datetime AS t2_datetime, \n",
        "                        t3.user1 AS t3_user1, t3.user2 AS t3_user2, t3.datetime AS t3_datetime\n",
        "                      FROM t1\n",
        "                      LEFT JOIN t2 ON t1.user2 = t2.user1\n",
        "                      AND t1.user1 != t2.user2\n",
        "                      LEFT JOIN t3 ON t2.user2 = t3.user1\n",
        "                      AND t2.user1 != t3.user2\n",
        "                      WHERE t1.user1 == t3.user2\n",
        "                      ORDER BY t1.user1, t1.lifetime\"\"\")\n",
        "# edges_3join.show(20)\n",
        "# for table1 user1, each triangle will appear twice in the results table "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlp69kQ9SdcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edges_3join.createOrReplaceTempView(\"t1\")\n",
        "# calculate the date when the triangle formed by selecting the latest date of the transaction between three users\n",
        "# then calculate the lifetime for t1_user1 when the triangle formed \n",
        "edges_3join_tridate = spark.sql(\"\"\"\n",
        "                                SELECT t1_user1, t2_user1, t3_user1,\n",
        "                                ceil(DATEDIFF(GREATEST(t1_datetime, t2_datetime, t3_datetime), t1_start_date)/30)\n",
        "                                AS triangle_lifetime\n",
        "                                FROM t1\n",
        "                                \"\"\")\n",
        "# edges_3join_tridate.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPvy9OIQSea4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edges_3join_tridate.createOrReplaceTempView(\"t1\")\n",
        "# get the triangles of lifetime <= 12, and count the number of triangles group by each user and lifetime\n",
        "num_triangles = spark.sql(\"\"\"\n",
        "                                SELECT t1_user1 AS user1, triangle_lifetime AS lifetime,\n",
        "                                COUNT(*)/2 AS num_triangles\n",
        "                                FROM t1\n",
        "                                WHERE triangle_lifetime <= 12\n",
        "                                GROUP BY t1_user1, triangle_lifetime\n",
        "                                ORDER BY t1_user1, triangle_lifetime\n",
        "                                \"\"\")\n",
        "# num_triangles.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XzPKPzsSg0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_triangles.createOrReplaceTempView(\"t1\")\n",
        "user_lifetime.createOrReplaceTempView(\"t2\")\n",
        "# get # triangles for consecutive 0-12 months\n",
        "num_triangles_one_year = spark.sql(\"\"\"\n",
        "                                SELECT user1, lifetime, SUM(num_triangles) AS num_triangles\n",
        "                                FROM(\n",
        "                                  SELECT user1, lifetime, num_triangles\n",
        "                                  FROM t1\n",
        "                                  UNION\n",
        "                                  SELECT user1, lifetime, 0 AS num_triangles\n",
        "                                  FROM t2) temp_table\n",
        "                                GROUP BY user1, lifetime\n",
        "                                ORDER BY user1, lifetime\n",
        "                                \"\"\")\n",
        "# num_triangles_one_year.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsyeIAbKSigY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the cumulative # triangles in each lifetime month for each user\n",
        "num_tri_window = Window.partitionBy(\"user1\").orderBy(\"lifetime\") \n",
        "from pyspark.sql.functions import sum, col\n",
        "num_triangles_one_year = num_triangles_one_year.withColumn(\"cum_num_triangles\", \n",
        "                                                       sum(\"num_triangles\").over(num_tri_window)).sort(col(\"user1\"), \n",
        "                                                                                                     col(\"lifetime\"))\n",
        "# num_triangles_one_year.show(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPzx4usYSnEa",
        "colab_type": "text"
      },
      "source": [
        "### Now run regression for Q11!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ01pBVKSo2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transaction_count.createOrReplaceTempView(\"txn_count\")\n",
        "num_friends_one_year.createOrReplaceTempView(\"num_friends\")\n",
        "num_friends_of_friends_one_year.createOrReplaceTempView(\"num_fof\")\n",
        "num_triangles_one_year.createOrReplaceTempView(\"num_tri\")\n",
        "pr_df.createOrReplaceTempView(\"pr_df\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZEhPPQUSo5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# join tables to combine user lifetime, # friends, # fof, # of triangles, page rank and total transactions (y)\n",
        "regression11_input = spark.sql(\"\"\"SELECT num_friends.user1, num_friends.lifetime, cum_num_friends AS num_friends, \n",
        "                  cum_num_fnd_of_fnd AS num_friends_of_friends, \n",
        "                  cum_num_triangles AS num_triangles, PageRank AS page_rank, num_transaction\n",
        "                  FROM num_friends \n",
        "                  JOIN num_fof ON num_friends.user1 = num_fof.user1\n",
        "                  AND num_friends.lifetime = num_fof.lifetime\n",
        "                  JOIN num_tri ON num_friends.user1 = num_tri.user1\n",
        "                  AND num_friends.lifetime = num_tri.lifetime\n",
        "                  JOIN txn_count USING (user1)\n",
        "                  JOIN pr_df USING (user1)\n",
        "                  ORDER BY user1, lifetime\"\"\")\n",
        "# regression11_input.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPCmAEW9SpFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regression11_input.createOrReplaceTempView(\"regression11_input\")\n",
        "regression11_input_lifetime0 = spark.sql(\"select * from regression11_input where lifetime=0 \")\n",
        "regression11_input_lifetime1 = spark.sql(\"select * from regression11_input where lifetime=1 \")\n",
        "regression11_input_lifetime2 = spark.sql(\"select * from regression11_input where lifetime=2 \")\n",
        "regression11_input_lifetime3 = spark.sql(\"select * from regression11_input where lifetime=3 \")\n",
        "regression11_input_lifetime4 = spark.sql(\"select * from regression11_input where lifetime=4 \")\n",
        "regression11_input_lifetime5 = spark.sql(\"select * from regression11_input where lifetime=5 \")\n",
        "regression11_input_lifetime6 = spark.sql(\"select * from regression11_input where lifetime=6 \")\n",
        "regression11_input_lifetime7 = spark.sql(\"select * from regression11_input where lifetime=7 \")\n",
        "regression11_input_lifetime8 = spark.sql(\"select * from regression11_input where lifetime=8 \")\n",
        "regression11_input_lifetime9 = spark.sql(\"select * from regression11_input where lifetime=9 \")\n",
        "regression11_input_lifetime10 = spark.sql(\"select * from regression11_input where lifetime=10 \")\n",
        "regression11_input_lifetime11 = spark.sql(\"select * from regression11_input where lifetime=11 \")\n",
        "regression11_input_lifetime12 = spark.sql(\"select * from regression11_input where lifetime=12 \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1btgIwiGSpDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the monthly regression table as parquet to speed up the future regression\n",
        "regression11_input_lifetime2.coalesce(1).write.format(\"parquet\").mode(\"append\").save(\"regression_q11_m2.parquet\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i6kQ9QtSpA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv regression_q11_m2.parquet /content/drive/My\\ Drive/ConFiveDance/code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBa2893cSo_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.linalg import Vector\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDY51x0dS8f_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lifetimeMSE(inputdata):\n",
        "    Assembler = VectorAssembler(inputCols = ['lifetime', 'num_friends', 'num_friends_of_friends',\n",
        "                                             'num_triangles', 'page_rank'], \n",
        "                                outputCol ='features')\n",
        "    outputdata = Assembler.transform(inputdata)\n",
        "    model_df = outputdata.select('features','num_transaction')\n",
        "    train_df, test_df = model_df.randomSplit([0.7, 0.3], seed=1)\n",
        "    lin_reg = LinearRegression(labelCol ='num_transaction', featuresCol='features')\n",
        "    lr_model = lin_reg.fit(train_df)\n",
        "    test_results = lr_model.evaluate(test_df)\n",
        "    r_mse = test_results.rootMeanSquaredError\n",
        "    mse = r_mse**2\n",
        "    return mse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OaYpMaES-lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MSE_lifetime0 = lifetimeMSE(regression11_input_lifetime0)\n",
        "print(\"MSE of lifetime 0 is:\", MSE_lifetime0)\n",
        "\n",
        "MSE_lifetime1 = lifetimeMSE(regression11_input_lifetime1)\n",
        "print(\"MSE of lifetime 1 is:\", MSE_lifetime1)\n",
        "\n",
        "MSE_lifetime2 = lifetimeMSE(regression11_input_lifetime2)\n",
        "print(\"MSE of lifetime 2 is:\",MSE_lifetime2)\n",
        "\n",
        "MSE_lifetime3 = lifetimeMSE(regression11_input_lifetime3)\n",
        "print(\"MSE of lifetime 3 is:\", MSE_lifetime3)\n",
        "\n",
        "MSE_lifetime4 = lifetimeMSE(regression11_input_lifetime4)\n",
        "print(\"MSE of lifetime 4 is:\", MSE_lifetime4)\n",
        "\n",
        "MSE_lifetime5 = lifetimeMSE(regression11_input_lifetime5)\n",
        "print(\"MSE of lifetime 5 is:\", MSE_lifetime5)\n",
        "\n",
        "MSE_lifetime6 = lifetimeMSE(regression11_input_lifetime6)\n",
        "print(\"MSE of lifetime 6 is:\", MSE_lifetime6)\n",
        "\n",
        "MSE_lifetime7 = lifetimeMSE(regression11_input_lifetime7)\n",
        "print(\"MSE of lifetime 7 is:\", MSE_lifetime7)\n",
        "\n",
        "MSE_lifetime8 = lifetimeMSE(regression11_input_lifetime8)\n",
        "print(\"MSE of lifetime 8 is:\", MSE_lifetime8)\n",
        "\n",
        "MSE_lifetime9 = lifetimeMSE(regression11_input_lifetime9)\n",
        "print(\"MSE of lifetime 9 is:\", MSE_lifetime9)\n",
        "\n",
        "MSE_lifetime10 = lifetimeMSE(regression11_input_lifetime10)\n",
        "print(\"MSE of lifetime 10 is:\", MSE_lifetime10)\n",
        "\n",
        "MSE_lifetime11 = lifetimeMSE(regression11_input_lifetime11)\n",
        "print(\"MSE of lifetime 11 is:\", MSE_lifetime11)\n",
        "\n",
        "MSE_lifetime12 = lifetimeMSE(regression11_input_lifetime12)\n",
        "print(\"MSE of lifetime 12 is:\", MSE_lifetime12)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0EsRb8KzKl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# standardize PageRank so that the coefficients and standard errors of the variables would be on the same scale\n",
        "regression11_input_lifetime12.createOrReplaceTempView('q11')\n",
        "q11_std_input = spark.sql(\"\"\" select lifetime, num_friends, num_friends_of_friends,\n",
        "num_triangles, (page_rank - avg(page_rank) over())/(std(page_rank) over()) AS std_page_rank, num_transaction\n",
        "FROM q11\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEh6f1KPS-zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run the regression lifetime 12, get the MSE and and see the important features\n",
        "Assembler = VectorAssembler(inputCols = [ 'num_friends', 'num_friends_of_friends',\n",
        "                                          'num_triangles', 'page_rank'], \n",
        "                            outputCol ='features')\n",
        "outputdata = Assembler.transform(q11_std_input)\n",
        "model_df = outputdata.select('features','num_transaction')\n",
        "train_df, test_df = model_df.randomSplit([0.7, 0.3], seed=1)\n",
        "lin_reg = LinearRegression(labelCol ='num_transaction', featuresCol='features')\n",
        "lr_model = lin_reg.fit(train_df)\n",
        "test_results = lr_model.evaluate(test_df)\n",
        "r_mse = test_results.rootMeanSquaredError\n",
        "MSE_lifetime12 = r_mse**2\n",
        "trainingSummary = lrModel.summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcYS_Tb-zAOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Coefficients: %s\" % str(lr_model.coefficients))\n",
        "print(\"P Values: \" + str(trainingSummary.pValues))\n",
        "print(\"Coefficient Standard Errors: \" + str(trainingSummary.coefficientStandardErrors))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oApA72DsTKRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MSE_11 = []\n",
        "MSE_11.extend([MSE_lifetime0, MSE_lifetime1, MSE_lifetime2, MSE_lifetime3, MSE_lifetime4, MSE_lifetime5, MSE_lifetime6, \n",
        "            MSE_lifetime7, MSE_lifetime8, MSE_lifetime9, MSE_lifetime10, MSE_lifetime11, MSE_lifetime12])\n",
        "MSE_11"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqeJeMolTMbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Lifetime_x = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
        "plt.plot(Lifetime_x, MSE_11, 'ro--', linewidth=2, markersize=8) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpnAq2fW8o8P",
        "colab_type": "text"
      },
      "source": [
        "## Q12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNTvRada8oUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read the output of Q4 that we saved as parquet\n",
        "cat_parquet = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/dynamic_profile.parquet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECLbzaYaLfs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the running average of spending profile to make the spending cumulative\n",
        "cat_parquet.createOrReplaceTempView('spend_prof')\n",
        "running_avg_sp = spark.sql(\"\"\" SELECT user1, lifetime, \n",
        "AVG(activity) OVER (PARTITION BY user1 ORDER BY lifetime) AS Activity,\n",
        "AVG(Cash) OVER (PARTITION BY user1 ORDER BY lifetime) AS Cash,\n",
        "AVG(Event) OVER (PARTITION BY user1 ORDER BY lifetime) AS Event,\n",
        "AVG(Food) OVER (PARTITION BY user1 ORDER BY lifetime) AS Food,\n",
        "AVG(Illegal_Sarcasm) OVER (PARTITION BY user1 ORDER BY lifetime) AS Illegal_Sarcasm,\n",
        "AVG(Not_classified) OVER (PARTITION BY user1 ORDER BY lifetime) AS Not_classified,\n",
        "AVG(People) OVER (PARTITION BY user1 ORDER BY lifetime) AS People,\n",
        "AVG(Transportation) OVER (PARTITION BY user1 ORDER BY lifetime) AS Transportation,\n",
        "AVG(Travel) OVER (PARTITION BY user1 ORDER BY lifetime) AS Travel,\n",
        "AVG(Utility) OVER (PARTITION BY user1 ORDER BY lifetime) AS Utility\n",
        "FROM spend_prof ORDER BY user1, lifetime\n",
        "\"\"\")\n",
        "running_avg_sp.show(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS7p0Ho196lb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dynamic_social_12 = inputdata.select('user1', 'user2', 'datetime').union(inputdata.select('user2', 'user1', 'datetime'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWOYL2jW98l1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use window function to get the date of the first transaction of each user1\n",
        "window1 = Window.partitionBy(\"user1\").orderBy(\"datetime\") \n",
        "window2 = Window.partitionBy(\"user2\").orderBy(\"datetime\") \n",
        "dynamic_social_12 = dynamic_social.withColumn(\"user1_start_date\", \n",
        "                                              min(\"datetime\").over(window1)).withColumn(\"user2_start_date\", \n",
        "                                                                                       min(\"datetime\").over(window2))\n",
        "# dynamic_social_12.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvwRroSU-AER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dynamic_social_12.createOrReplaceTempView(\"table1\")\n",
        "# calculate the lifetime month of the user1 for each line of transaction\n",
        "ds_12 = spark.sql(\"\"\"SELECT user1, user2, datetime, user1_start_date, \n",
        "                           ceil(datediff(datetime, user1_start_date)/30) AS user1_lifetime,\n",
        "                           user2_start_date,\n",
        "                           ceil(datediff(datetime, user2_start_date)/30) AS user2_lifetime\n",
        "                           FROM table1\n",
        "                           WHERE ceil(datediff(datetime, user1_start_date)/30) <=12 \n",
        "                           \"\"\")\n",
        "ds_12.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn0DMWt0-DuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds_12.createOrReplaceTempView(\"t1\")\n",
        "running_avg_sp.createOrReplaceTempView(\"t2\")\n",
        "\n",
        "reg_12 = spark.sql(\"\"\"SELECT t1.user1, t1.user2, t1.user1_lifetime AS lifetime,\n",
        "                    Activity, Cash, Event, Food, Illegal_Sarcasm, Not_classified,\n",
        "                    People, Transportation, Travel, Utility\n",
        "                    FROM t1\n",
        "                    JOIN t2 ON t1.user2 = t2.user1 \n",
        "                    AND t1.user2_lifetime = t2.lifetime\n",
        "                    \"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPgD0NKs-GF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read the regression input of the Q11 lifetime 0 we saved as parquet \n",
        "reg_11_m0 = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/regression_q11_m0.parquet')\n",
        "reg_11_m0.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHEoJQqf-RwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg_12.createOrReplaceTempView(\"t1\")\n",
        "reg_11_m0.createOrReplaceTempView(\"t2\")\n",
        "reg_q12_m0 = spark.sql(\"\"\"\n",
        "                      SELECT *\n",
        "                      FROM t1\n",
        "                      JOIN t2 USING (user1, lifetime) \"\"\")\n",
        "reg_q12_m0.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XptE2BDY-OEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg_q12_m0.coalesce(1).write.format(\"parquet\").mode(\"append\").save(\"reg_q12_m0.parquet\")\n",
        "!mv reg_q12_m0.parquet /content/drive/My\\ Drive/ConFiveDance/code\n",
        "\n",
        "reg_q12_m1.coalesce(1).write.format(\"parquet\").mode(\"append\").save(\"reg_q12_m1.parquet\")\n",
        "!mv reg_q12_m1.parquet /content/drive/My\\ Drive/ConFiveDance/code\n",
        "\n",
        "reg_q12_m2.coalesce(1).write.format(\"parquet\").mode(\"append\").save(\"reg_q12_m2.parquet\")\n",
        "!mv reg_q12_m2.parquet /content/drive/My\\ Drive/ConFiveDance/code\n",
        "\n",
        "reg_q12_m3.coalesce(1).write.format(\"parquet\").mode(\"append\").save(\"reg_q12_m3.parquet\")\n",
        "!mv reg_q12_m3.parquet /content/drive/My\\ Drive/ConFiveDance/code\n",
        "\n",
        "reg_q12_m4.coalesce(1).write.format(\"parquet\").mode(\"append\").save(\"reg_q12_m4.parquet\")\n",
        "!mv reg_q12_m4.parquet /content/drive/My\\ Drive/ConFiveDance/code\n",
        "\n",
        "reg_q12_m5.coalesce(1).write.format(\"parquet\").mode(\"append\").save(\"reg_q12_m5.parquet\")\n",
        "!mv reg_q12_m5.parquet /content/drive/My\\ Drive/ConFiveDance/code\n",
        "\n",
        "reg_q12_m6.coalesce(1).write.format(\"parquet\").mode(\"append\").save(\"reg_q12_m6.parquet\")\n",
        "!mv reg_q12_m6.parquet /content/drive/My\\ Drive/ConFiveDance/code\n",
        "\n",
        "reg_q12_m7.coalesce(1).write.format(\"parquet\").mode(\"append\").save(\"reg_q12_m7.parquet\")\n",
        "!mv reg_q12_m7.parquet /content/drive/My\\ Drive/ConFiveDance/code\n",
        "\n",
        "reg_q12_m8.coalesce(1).write.format(\"parquet\").mode(\"append\").save(\"reg_q12_m8.parquet\")\n",
        "!mv reg_q12_m8.parquet /content/drive/My\\ Drive/ConFiveDance/code\n",
        "\n",
        "reg_q12_m9.coalesce(1).write.format(\"parquet\").mode(\"append\").save(\"reg_q12_m9.parquet\")\n",
        "!mv reg_q12_m9.parquet /content/drive/My\\ Drive/ConFiveDance/code\n",
        "\n",
        "reg_q12_m10.coalesce(1).write.format(\"parquet\").mode(\"append\").save(\"reg_q12_m10.parquet\")\n",
        "!mv reg_q12_m10.parquet /content/drive/My\\ Drive/ConFiveDance/code\n",
        "\n",
        "reg_q12_m11.coalesce(1).write.format(\"parquet\").mode(\"append\").save(\"reg_q12_m11.parquet\")\n",
        "!mv reg_q12_m11.parquet /content/drive/My\\ Drive/ConFiveDance/code\n",
        "\n",
        "reg_q12_m12.coalesce(1).write.format(\"parquet\").mode(\"append\").save(\"reg_q12_m12.parquet\")\n",
        "!mv reg_q12_m12.parquet /content/drive/My\\ Drive/ConFiveDance/code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2HZ7LYE-X0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regression_input_q12_m0 = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/reg_q12_m0.parquet')\n",
        "regression_input_q12_m1 = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/reg_q12_m1.parquet')\n",
        "regression_input_q12_m2 = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/reg_q12_m2.parquet')\n",
        "regression_input_q12_m3 = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/reg_q12_m3.parquet')\n",
        "regression_input_q12_m4 = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/reg_q12_m4.parquet')\n",
        "regression_input_q12_m5 = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/reg_q12_m5.parquet')\n",
        "regression_input_q12_m6 = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/reg_q12_m6.parquet')\n",
        "regression_input_q12_m7 = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/reg_q12_m7.parquet')\n",
        "regression_input_q12_m8 = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/reg_q12_m8.parquet')\n",
        "regression_input_q12_m9 = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/reg_q12_m9.parquet')\n",
        "regression_input_q12_m10 = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/reg_q12_m10.parquet')\n",
        "regression_input_q12_m11 = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/reg_q12_m11.parquet')\n",
        "regression_input_q12_m12 = spark.read.parquet('/content/drive/My Drive/ConFiveDance/code/reg_q12_m12.parquet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx9v1T6a-bPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lifetimeMSE(inputdata):\n",
        "    Assembler = VectorAssembler(inputCols = ['Activity', 'Cash', 'Event', 'Food', 'Illegal_Sarcasm',\n",
        "                                              'Not_classified', 'People', 'Transportation', 'Travel', 'Utility',\n",
        "                                              'num_friends', 'num_friends_of_friends',\n",
        "                                             'num_triangles', 'page_rank'], \n",
        "                                outputCol ='features')\n",
        "    outputdata = Assembler.transform(inputdata)\n",
        "    model_df = outputdata.select('features','num_transaction')\n",
        "    train_df, test_df = model_df.randomSplit([0.7, 0.3], seed=1)\n",
        "    lin_reg = LinearRegression(labelCol ='num_transaction', featuresCol='features')\n",
        "    lr_model = lin_reg.fit(train_df)\n",
        "    test_results = lr_model.evaluate(test_df)\n",
        "    r_mse = test_results.rootMeanSquaredError\n",
        "    mse = r_mse**2\n",
        "    return mse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBPLUClW-ljN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MSE_lifetime0 = lifetimeMSE(regression_input_q12_m0)\n",
        "print(\"MSE of lifetime 0 is:\", MSE_lifetime0)\n",
        "\n",
        "MSE_lifetime1 = lifetimeMSE(regression_input_q12_m1)\n",
        "print(\"MSE of lifetime 1 is:\", MSE_lifetime1)\n",
        "\n",
        "MSE_lifetime2 = lifetimeMSE(regression_input_q12_m2)\n",
        "print(\"MSE of lifetime 2 is:\",MSE_lifetime2)\n",
        "\n",
        "MSE_lifetime3 = lifetimeMSE(regression_input_q12_m3)\n",
        "print(\"MSE of lifetime 3 is:\", MSE_lifetime3)\n",
        "\n",
        "MSE_lifetime4 = lifetimeMSE(regression_input_q12_m4)\n",
        "print(\"MSE of lifetime 4 is:\", MSE_lifetime4)\n",
        "\n",
        "MSE_lifetime5 = lifetimeMSE(regression_input_q12_m5)\n",
        "print(\"MSE of lifetime 5 is:\", MSE_lifetime5)\n",
        "\n",
        "MSE_lifetime6 = lifetimeMSE(regression_input_q12_m6)\n",
        "print(\"MSE of lifetime 6 is:\", MSE_lifetime6)\n",
        "\n",
        "MSE_lifetime7 = lifetimeMSE(regression_input_q12_m7)\n",
        "print(\"MSE of lifetime 7 is:\", MSE_lifetime7)\n",
        "\n",
        "MSE_lifetime8 = lifetimeMSE(regression_input_q12_m8)\n",
        "print(\"MSE of lifetime 8 is:\", MSE_lifetime8)\n",
        "\n",
        "MSE_lifetime9 = lifetimeMSE(regression_input_q12_m9)\n",
        "print(\"MSE of lifetime 9 is:\", MSE_lifetime9)\n",
        "\n",
        "MSE_lifetime10 = lifetimeMSE(regression_input_q12_m10)\n",
        "print(\"MSE of lifetime 10 is:\", MSE_lifetime10)\n",
        "\n",
        "MSE_lifetime11 = lifetimeMSE(regression_input_q12_m11)\n",
        "print(\"MSE of lifetime 11 is:\", MSE_lifetime11)\n",
        "\n",
        "MSE_lifetime12 = lifetimeMSE(regression_input_q12_m12)\n",
        "print(\"MSE of lifetime 12 is:\", MSE_lifetime12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq0Eq0uX51qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MSE_12 = []\n",
        "MSE_12.extend([MSE_lifetime0, MSE_lifetime1, MSE_lifetime2, MSE_lifetime3, MSE_lifetime4, MSE_lifetime5, MSE_lifetime6, \n",
        "            MSE_lifetime7, MSE_lifetime8, MSE_lifetime9, MSE_lifetime10, MSE_lifetime11, MSE_lifetime12])\n",
        "MSE_12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGIgovXw6DOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Lifetime_x = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
        "plt.plot(Lifetime_x, MSE_12, 'mo--', linewidth=2, markersize=8) \n",
        "\n",
        "plt.xlabel('lifetime')\n",
        "plt.ylabel('MSE')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}